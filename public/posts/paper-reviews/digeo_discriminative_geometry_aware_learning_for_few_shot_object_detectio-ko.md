---
title: 'DiGeo: Discriminative Geometry-Aware Learning for
Generalized Few-Shot Object Detection'
date: '2023-07-14'
tags: ['object detection', 'paper review']
---

### Abstract

일반화된 소수 샘플 객체 탐지는 풍부한 주석이 있는 기반 클래스 (base classes)와 제한된 훈련 데이터만 있는 새로운 클래스 (novel classes) 모두에서 정밀한 탐지를 달성하는 것을 목표로 합니다. 기존 접근 방식은 기반 클래스 성능을 희생하면서 소수 샘플 일반화를 향상시키거나, 새로운 클래스 적응에는 제한된 개선만 이루면서 기반 클래스 탐지에서 높은 정밀도를 유지합니다. 본 논문에서는 그 이유가 모든 클래스에 대한 불충분한 판별적 특징 학습 (Discriminative feature learning)에 있음을 지적합니다.

따라서 본 논문에서는 클래스 간 분리 (inter-class separation)와 클래스 내 압축성 (intra-class compactness)의 기하학 인지 특징 (Geometry-aware features)을 학습하기 위한 새로운 훈련 프레임워크인 DiGeo를 제안합니다.

특징 클러스터의 분리를 유도하기 위해, 오프라인 단체 등각 밀집 프레임 (simplex equiangular tight frame, ETF) 분류기를 도출합니다. 이 분류기의 가중치 (weights)는 클래스 중심 역할을 하며 최대 및 동등하게 분리됩니다. 각 클래스에 대한 클러스터를 압축하기 위해, 분류 손실에 적응형 클래스별 마진 (adaptive class-specific margins)을 포함하고 특징이 클래스 중심에 가까워지도록 장려합니다. 두 개의 소수 샘플 벤치마크 데이터셋과 하나의 긴 꼬리 데이터셋에 대한 실험적 연구는 단일 모델로 우리의 방법이 기반 클래스 탐지를 저해하지 않고 새로운 클래스에 대한 일반화를 효과적으로 개선할 수 있음을 입증합니다.

---

### Introduction

최근 몇 년 동안 딥 신경 모델과 대규모 훈련을 통한 객체 탐지는 엄청난 성장을 목격했습니다. 그러나 탐지 모델의 성공은 주석의 양과 품질에 크게 의존하며, 이는 비용과 시간이 많이 드는 주석 작업을 요구합니다. 또한, 기존 객체 탐지 모델은 제한된 수의 주석을 가진 클래스에서 성능이 떨어지는 반면, 인간은 소수의 관찰로부터 학습할 수 있습니다. 인간 시각 시스템과 탐지 모델 간의 격차를 줄이기 위해, 최근 연구들은 소수 샘플 객체 탐지 (FSOD, few-shot object detection) 설정 하에서 희귀 클래스에 대해 어떻게 잘 일반화할 수 있는지 조사해 왔습니다.

구체적으로, 풍부한 훈련 데이터가 있는 다수 샘플 클래스 (base classes)와 극히 제한된 훈련 데이터 (예: 클래스당 5개의 주석이 달린 인스턴스)가 있는 소수 샘플 클래스 (novel classes)가 주어졌을 때, FSOD는 모델이 새로운 클래스의 객체를 잘 탐지하기를 기대합니다.

본 논문에서 소수 샘플 객체 탐지에서 악영향의 원인이 불충분한 판별적 특징 학습 (discriminative feature learning)에 있으며, 이는 새로운 클래스에 대한 비효율적인 지식 적응과 base 클래스의 예기치 않은 지식 망각을 포함한다고 지적했습니다. 훈련 중 새로운 인스턴스가 극도로 제한적이기 때문에, 새로운 클래스의 대표적인 시각적 정보를 포착하고 base 클래스에서 학습된 지식을 새로운 클래스에 적응시키기 어렵습니다. 결과적으로 모델은 새로운 클래스를 구별하지 못하여 소수 샘플 적응이 약화됩니다. 다운 샘플링과 같은 균형 잡힌 훈련 전략은 base 세트의 다양한 훈련 샘플을 활용하지 못합니다. 따라서 base 클래스의 완전한 지식을 보존하기 어려워 과적합을 유발하고 탐지 점수를 더욱 감소시킵니다.

---

### Related Work

<img src="https://velog.velcdn.com/images/devjo/post/16ae15aa-15ff-4301-aa3c-dae18af3a474/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

#### $\text{FSOD}$

소수 샘플 객체 탐지 (FSOD)는 인스턴스 수준에서 소수 샘플 (새로운) 클래스의 객체를 탐지하는 것을 목표로 합니다. 적응 효율을 개선하기 위해, 메타 학습 (meta-learning) 및 전이 학습 (transfer-learning)을 기반으로 하는 접근 방식이 연구되고 있습니다.

메타 학습 접근 방식은 클래스 불가지론적 (class-agnostic) 메타 학습자를 학습하여 다른 이미지의 동일 클래스 인스턴스들을 정렬합니다. Faster-RCNN 프레임워크 내에서, 어텐션 기반 메타-RPN 및 메타-탐지기가 클래스 관련 제안 영역 proposals을 생성하고 인스턴스 정렬을 개선하기 위해 제안되었습니다. 또한, Transformer 및 YoLo 기반 접근 방식이 특징을 공동으로 추출하고 다중 스케일에서 특징을 정렬하기 위해 제안되었습니다.

전이 학습 접근 방식은 소수 샘플 적응을 위해 미세 조정 (finetuning)을 수행합니다. 구체적으로, TFA는 풍부한 기반 샘플로부터 기반 탐지기 (base detector)를 사전 훈련하고 새로운 클래스를 위해 미세 조정합니다. 적응 효율을 개선하기 위해 다중 스케일 특징 추출  및 대조 손실, 마진 균형, 변환 불변성과 같은 정규화가 사용됩니다. 최근, DeFRCN은 다른 손실로부터 역전파된 경사도를 조정하고 뛰어난 새로운 클래스 탐지 점수를 달성했습니다.

#### $\text{Generalized Few-Shot Object Detection}$

위에 언급된 모든 FSOD 접근 방식은 소수 샘플 적응 후에 기반 탐지에서의 정밀도가 희생됩니다. 이러한 현상은 도메인 격차 또는 분포 격차로 인해 모델이 기반 지식을 잊어버리는 다양한 비전 작업에서도 관찰되었습니다. Fan et al.이 지적했듯이, 이미지에는 novel 클래스와 base 클래스 모두의 인스턴스가 포함될 수 있으며 정규화 소수 샘플 미세 조정을 제안하고, base 탐지의 정밀도를 보존하기 위해 모델 앙상블 기술을 사용합니다. 그러나 novel 샘플 적응 효율은 필연적으로 제한됩니다.

---

### Method

단일 모델을 사용하여 두 마리 토끼를 모두 잡는 것을 목표로 합니다. 즉, base 탐지의 정밀도를 해치지 않으면서 novel 클래스에 대한 소수 샘플 적응 성능을 개선하는 것입니다. 모든 클래스를 구별하기 위한 특징 공간상의 명확한 경계를 만드는 것입니다. 본 논문에서는 이 아이디어를 두 가지 측면에서 실현합니다. 모든 클래스 간의 클래스 간 분리 (inter-class separation)와 각 클래스에 대한 클래스 내 압축성 (intra-class compactness)입니다.

#### Inter-Class Separation

우리는 클래스 중심 간의 쌍별 거리 (pairwise distances between class centers)를 최대화함으로써 클래스 간 분리를 실현합니다. 구체적으로, 각 $w_i$에 대해 우리는 다른 모든 가중치 $W \setminus {w_i}$와의 최소 거리를 최대화합니다.

$$
W^* = \operatorname{argmax}_W \sum_{i=1}^{N_c} \min_{j, i \ne j} \|w_i - w_j\|_2^2
$$

여기서 $N_c = N_b + N_n + 1$이고 모든 가중치 벡터는 동일한 노름을 가집니다. 특징 차원 $d \ge N_c - 1$일 때, $W^*$에서의 모든 클래스 중심 쌍의 거리는 동일해야 합니다. 또한, $\|w_i\| = 1$이 주어지면 모든 클래스 중심 쌍 사이의 각도도 동일한 값을 가집니다. 이러한 방식으로, 클래스 중심이 특징 공간에 균등하게 분포되기를 기대합니다. 이 경우, $W^*$는 단체 등각 밀집 프레임 (simplex equiangular tight frame, ETF)과 동일합니다.

#### Intra-Class Compactness

우리는 특징 클러스터를 압축하고 샘플들을 $W^*$에 할당된 중심에 가깝게 밀어붙임으로써 클래스 내 압축성을 실현합니다. 여기에는 두 가지 과제가 있습니다. 첫째, base 클래스와 novel 클래스의 훈련 샘플 수가 극도로 불균형하여 특징 공간에서 novel 클래스의 경계를 결정하기 어렵습니다. 둘째, novel 클래스의 수 $|D_n|$이 base 클래스의 수 $|D_b|$보다 훨씬 작기 때문에 네트워크는 novel 클래스에 대해 더 적은 양의 경사도 (positive gradients)를 받습니다. 이로 인해 novel 클래스의 인스턴스 특징이 클래스 중심에서 더 멀어지고 판별력이 떨어집니다.

긴 꼬리 인식에서의 로짓 조정 (logit adjustment)의 성공에서 영감을 받아, 로짓에 클래스별 마진을 적용하여 분류 손실을 수정하고 base 클래스와 novel 클래스 간의 최적화 균형을 맞춥니다. 구체적으로, 바운딩 박스 주석의 빈도를 사전 지식으로 사용하여 클래스별 마진을 계산합니다.

$$
m_c = \begin{cases} -\log(p_c) , & \text{if } c \in C_b \cup C_n \\ -\log(p_-) , & \text{if } c = c^- \end{cases}
$$

여기서 $p_c$는 클래스 $c$에 대한 바운딩 박스 주석의 빈도이며, $p_-$는 분류기를 훈련하기 위한 배경 박스 (background boxes)의 추정 확률이며, $p_- + \sum_{c \in C_b \cup C_n} p_c = 1$입니다. 직관적으로, 데이터가 적은 클래스에는 해당 클래스의 학습을 보장하기 위해 더 큰 마진이 할당됩니다.

샘플 $x$에 대한 로짓 출력이 $v = \{v_c\}_{c \in C}$라고 가정할 때, 우리는 마진을 로짓에 추가하여 다음의 사전 마진 교차 엔트로피 손실을 사용합니다.

$$
L_{\text{prior}}(x) = - \sum_{c \in C} y_c \cdot \log \frac{\exp(v_c - m_c)}{\sum_{c' \in C} \exp(v_{c'} - m_{c'})}
$$

여기서 $y_c$는 $c$가 정답 레이블일 경우 1이고, 그렇지 않으면 $y_c = 0$입니다. 모든 마진 $m_c$가 0으로 설정되면 사전 마진 손실은 바닐라 교차 엔트로피 손실로 감소합니다. 마진은 사전 분포를 기반으로 얻어지며 훈련 중에 고정되므로, 이 기준선을 Prior라고 명명합니다.

마진 기반 손실은 모든 제안 proposals에 대해 계산되지만, 제안을 통해 마진을 정확하게 계산하는 것은 시간이 많이 걸립니다. 따라서 우리는 모든 주석이 달린 바운딩 박스 인스턴스에 대해 사전 마진을 얻습니다. 이 경우 제안 기반 손실과 인스턴스 기반 마진 사이에 불일치가 발생합니다. 이 격차를 완화하기 위해 우리는 사전을 기반으로 마진을 적응적으로 학습할 것을 제안했습니다.

---

### Conclusion

본 논문에서 판별적 특징 학습 (discriminative feature learning)의 관점에서 일반화된 소수 샘플 객체 탐지를 재검토했습니다. 더 나아가, 클래스 간 분리와 클래스 내 압축성을 위한 단순하지만 효과적인 프레임워크인 DiGeo학습을 제안했습니다.

실험은 base 클래스 탐지를 저해하지 않고 novel 클래스에 대한 일반화를 개선하며, 긴 꼬리 객체 탐지로 확장될 수 있음을 입증합니다. 향후 연구에서는 객체 탐지에서 특징의 원하는 속성을 계속 조사하고 도메인 적응과 같은 더 현실적인 시나리오에 적용할 것입니다.

---

### 참고 자료

[원본 경로 #1](https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_DiGeo_Discriminative_Geometry-Aware_Learning_for_Generalized_Few-Shot_Object_Detection_CVPR_2023_paper.pdf)
