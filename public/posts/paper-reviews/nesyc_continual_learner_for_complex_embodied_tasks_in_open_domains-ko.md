---
title: 'NESYC: A NEURO-SYMBOLIC CONTINUAL LEARNER
FOR COMPLEX EMBODIED TASKS IN OPEN DOMAINS'
date: '2025-09-10'
tags: ['embodied ai', 'paper review']
---

### Abstract

실행 가능한 지식을 일반화하여 구현체 에이전트가 개방형 도메인 환경에서 복잡한 작업을 보다 효과적으로 처리할 수 있도록 하는 신경-기호적 접근 방식을 탐색합니다. 구현체 에이전트의 주요 과제는 제한된 경험이 에이전트를 기존 지식에 국한시키기 때문에 다양한 환경과 상황 전반에 걸쳐 지식을 일반화하는 것입니다.

이 문제를 해결하기 위해 가설-연역적 모델 (hypothetico-deductive model)을 모방하는 새로운 프레임워크인 NESYC를 소개합니다. 이는 거대 언어 모델 (LLMs)과 기호 도구를 함께 사용하여 제한된 경험으로부터 지식을 지속적으로 공식화하고 검증하는 신경-기호적 지속 학습자 (continual learner)입니다.

구체적으로, 대조 일반성 개선 체계를 고안했습니다. 이 체계는 LLM을 사용하여 가설을 반복적으로 생성하고 기호 도구를 통해 대조적 검증을 수행합니다. 이 체계는 허용 가능한 행동에 대한 정당성을 강화하는 동시에 허용 불가능한 행동의 추론을 최소화합니다.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/0263ccb1-c4bb-4d1e-8e95-87a7b180925d/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

LLMs을 기호 도구와 통합하는 방식에서의 최근 발전은 구현 작업 계획 (embodied task planning)에 많은 주목을 받아왔습니다. 하지만 이러한 시스템들은 개방형 도메인에서 아직 철저히 탐색되지 않았습니다. 개방형 도메인에서는 환경이 미리 정의된 작업이나 지식으로 제한되지 않으며, 구현체 에이전트가 다양한 시나리오를 관리해야 합니다. 전통적인 접근 방식은 전문가 수준의 실행 가능한 지식에 대한 기호적 표현에 의존하므로, 실제 상황에서의 적용 가능성과 효율성이 제한됩니다. 개방형 도메인의 예측 불가능하고 동적인 특성은 종종 지식의 불완전성 및 불일치로 이어져 구현체 에이전트의 의사 결정 프로세스를 복잡하게 만듭니다.

#### 개방형 도메인의 과제 (Challenges in Open-Domains)

신경-기호적 시스템에서 개방형 도메인 환경에서의 이전 실행 가능한 지식의 일반화는 다음과 같은 실질적인 과제를 제시합니다.

$\Rightarrow$ 지식을 익숙하지 않은 환경에 적용하는 데 유연성이 부족합니다.

$\Rightarrow$ 이전 지식과 새로운 환경 사이의 간극을 좁히는 방법이 제한적이어서 복잡한 상황에서 반복적인 행동 오류를 초래합니다.

$\Rightarrow$ 레이블링된 경험을 유지하지 못하여 발생하는 행동 어포던스의 오분류 또는 불충분한 피드백은 에이전트의 지식 일반화 능력과 의사 결정 개선 능력을 저해합니다.

#### The NESYC Framework

개방형 도메인에서 신경-기호적 접근 방식을 채택함으로써 발생하는 문제들을 해결하기 위해, 가설-연역적 모델에서 영감을 얻었습니다. 이 모델은 경험을 통한 반증을 강조하며, 가설을 지속적으로 형성하고, 사용 가능한 관찰에 대해 엄격하게 테스트하며, 반복적으로 수정하는 과학적 탐구 프로세스를 모방합니다.

이 모델에 따라, 귀납적 추론과 연역적 추론을 교차하는 지식 일반화 전략을 탐색하며, 개방형 도메인에 적용 가능한 지식을 일반화하고 구현체 에이전트가 예측 불가능한 상황에 더 효과적으로 적응할 수 있도록 하는 것을 목표로 합니다.

---

### Related Works

#### 1. 귀납 논리 프로그래밍(Inductive logic programming, ILP)

ILP는 학습된 모델이 논리 프로그램, 즉 가설 (일련의 규칙)으로 표현되며, 예제와 배경 지식의 조합으로부터 도출되는 기계 학습 기술입니다. 이 일반적인 설정은 해석으로부터 학습(Learning from Interpretations, LFI)이며 사실들의 집합으로 표현된 해석입니다.

배경 지식을 나타내는 프로그램 BK와 긍정 예제 집합 $E^+$ 및 부정 예제 집합 $E^-$가 주어지면, 목표는 다음을 만족하는 최적의 가설 $H$를 찾는 것입니다.

$$
\begin{cases} \forall e \in E^+, & e \text{ is an interpretation of } H \cup \text{BK}. \\ \forall e \in E^-, & e \text{ is not an interpretation of } H \cup \text{BK}. \end{cases}
$$

여기서 BK는 전통적인 기계 학습의 특징과 유사하게 기능하지만, 관계 및 예제와 관련된 정보를 포함할 수 있으므로 더 표현력이 풍부합니다.

#### 2. 응답 집합 프로그래밍(Answer set programming, ASP)

ASP는 계획과 같은 복잡한 조합 문제를 해결하는 데 매우 적합한 선언적 프로그래밍 패러다임이며, 특히 구현체 환경의 역학과 행동이 미래 상태를 변경할 수 있는 비단조적 도메인에서 유용합니다.

$$
\text{A} \text{ :- } B_1, \dots, B_m, \text{ not } B_{m+1}, \dots, \text{ not } B_n
$$

이 일반적인 형태에서, 규칙은 머리 ($\text{head, A}$)와 몸체 ($\text{body, } B_1, \dots, \text{ not } B_n$)로 구성되며, 각 $\text{A}$와 $B_i$ ($1 \le i \le n$)는 아톰 ($\text{atom}$)입니다. 머리는 결론을 나타내고, 몸체는 조건을 명시하는데, 여기에는 참이어야 하는 긍정 조건 ($B_1, \dots, B_m$)과 $\text{not}$이 실패로서의 부정 ($\text{negation as failure, NAF}$)을 나타내는 부정 조건 ($\text{not } B_{m+1}, \dots, \text{ not } B_n$)이 포함됩니다. $\text{NAF}$는 반대되는 증거가 제공되지 않는 한 부정된 조건이 거짓이라고 가정합니다. 몸체가 비어 있는 규칙은 사실 (예: $\text{A}$)이며, 머리가 비어 있는 규칙은 제약 조건으로, 충족되어서는 안 되는 조건을 나타냅니다.

#### 3. PROBLEM FORMULATION

$$
\pi^* = \operatorname*{arg\ max}_{\pi} \mathbb{E}_{d \sim D} \left[ \sum_{t} \text{SR}(s_t, \pi(\cdot \mid o_t, i_d)) \right]
$$

개방형 도메인 구현 작업 계획 문제는 튜플 $(D, S, A, F)$로 공식화됩니다. $D$는 개방형 도메인 환경의 도메인 공간, $S$는 상태 공간, 에이전트는 각 시간 단계에서 상태 $s \in S$에 대한 부분적인 정보를 제공하는 **관찰 $o_t \in \Omega$**를 인지하게 되며 $A$는 행동 공간입니다.

---

### Methods

<img src="https://velog.velcdn.com/images/devjo/post/8fecd7e6-1539-45f9-8d20-4221f5aec253/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

개방형 도메인 환경에서 구현체 에이전트를 위한 실행 가능한 지식을 일반화하도록 설계된 신경-기호적 지속 학습자 NESYC를 제안합니다. 에이전트의 제한된 경험을 효과적으로 활용하기 위해, 이 프레임워크는 LLMs와 기호 도구의 능력을 통합합니다.

#### 규칙 재공식화 (RULE REFORMULATION)

경험 집합 $T$에서 파생된 행동 전제 조건 및 효과에 대한 인과적 규칙을 나타내는 일반화된 지식 $R$을 재공식화합니다. 이를 달성하기 위해, NESYC는 ILP를 기반으로 하는 대조 일반성 개선 체계를 사용합니다.

$T$의 경험은 행동 어포던스를 기반으로 긍정 예제 $E^+$와 부정 예제 $E^-$로 구성된 예제 집합 $E$로 변환됩니다. 일반성 개선 프로세스는 가설 생성기 $\Phi_{\text{hyp}}$와 가설 해석기 $\Psi_{\text{interp}}$에 의해 구동되는 반복적이고 성찰적인 과정이며, 이들은 협력적으로 가설을 개선합니다. 이 프로세스를 통해, $R$이 얻어질 때까지 가설 $H$의 해석 가능성은 점진적으로 향상되며, $E^+$와 $E^-$에 대한 논리적 정당성과 추론을 강화합니다.

긍정 및 부정 예제를 모두 만족하는 가설 $H$를 유도하기 위해, LLM이 배경 지식 BK를 추출하도록 안내합니다. 이는 맥락을 향상시키고 가설이 예제와 정렬되도록 용이하게 합니다. 그런 다음 ILP의 $\theta$-포함 기술 ($\theta$-subsumption technique$)을 배치 샘플링 전략과 결합하여 통합하는 구조화된 프롬프트를 사용하여 BK를 통해 $H$를 생성합니다. $\theta$-포함 기술은 하나의 절이 다른 절을 의미하도록 만드는 대입 $\theta$를 찾음으로써 한 절이 다른 절보다 더 일반적인지 여부를 결정할 수 있도록 합니다. 이 프로세스를 단순화하기 위해, 우리는 포함 사고의 사슬 (subsumption Chain-of-Thought, CoT) 프롬프트 ($l_{\text{sub}}$로 표기)를 통해 LLMs의 다단계 추론 능력을 활용합니다. 가설 생성기 $\Phi_{\text{hyp}}$는 다음과 같이 정의됩니다.

$$
\Phi_{\text{hyp}} : (B, H_b^{i-1}, l_{\text{sub}}, l_{\text{fdb}}^{i-1}) \to (H_b^i, \text{BK}) \text{ where } B \sim E
$$

여기서 $B$는 $k$개의 무작위 예제 배치이고, $H_b^i$는 배치 반복 $b$에서의 가설입니다.

#### 규칙 적용 (RULE APPLICATION)

일반화된 지식 $R$은 사용자 지침 $i$에 의해 지정된 구현 작업을 완료하는 데 사용됩니다. 구체적으로, NESYC는 ASP를 활용하여 행동 계획을 위한 기호 도구와 메모리 기반 모니터링 체계를 사용합니다.

작업 실행 동안, 오류 처리기 $\Phi_{\text{err}}$는 행동 실행기 $\Phi_{\text{exe}}$를 통해 환경으로부터의 상호 작용 경험을 관리하고, 이를 작업 메모리 $M$에 저장합니다. 허용 불가능한 행동이 감지되면, $\Phi_{\text{err}}$은 $M$이 경험 집합 $T$에 통합되는 (i) 단계로 다시 진입하여 $R$의 개선을 트리거합니다. 개선된 $R$을 통해 NESYC는 예측 불가능한 상황에 효과적으로 적응합니다.

작업 계획기(Task planner)는 행동 계획을 계산할 때 $(R, s_t, g)$를 취하는 기호 도구가 사용됩니다. 여기서 $R$은 행동 전제 조건 및 효과에 대한 일반화된 지식, $s_t$는 현재 상태, $g$는 목표 상태입니다.

행동 실행기(action executor)는 작업 계획기 $\Psi_{\text{plan}}$에 의해 추론된 행동 계획 $P$로부터, 행동 실행기 $\Phi_{\text{exe}}$는 현재 단계 $t$부터 환경에서 관련 행동을 수행하기 위해 개별 계획을 선택할 수 있습니다. 즉, $\Phi_{\text{exe}} : (P, s_t, g) \to a_t$입니다. $\Phi_{\text{exe}}$는 행동 $a_t$를 수행하며, 환경으로부터의 관찰 $o_{t+1}$을 취한 행동의 결과와 함께 오류 처리기 $\Phi_{\text{err}}$로 전송합니다.

오류 처리기(error handler)는 예측된 상태 변화와 실제 관찰 사이의 일관성을 유지하기 위해, 궤적 샘플의 메모리 기반 보존을 사용하여 작업 실행을 모니터링합니다. 구현체 환경의 동적인 특성으로 인해, $\Psi_{\text{plan}}$을 기반으로 하는 계획은 종종 작업 완료에 미치지 못합니다. 실행 결과를 기반으로, $\Phi_{\text{err}}$은 행동 어포던스 $c_t$를 측정하고 다음 관찰 $o_{t+1}$을 재작성하여 환경에 대한 더 주의 깊은 표현을 제공합니다.

---

### Conclusion

이 프레임워크는 대조 일반성 개선 및 메모리 기반 모니터링이라는 두 가지 체계를 통해 신경-기호적 접근 방식을 적용하며, 이는 지속 학습 방식으로 귀납적 및 연역적 지식 개선의 교차를 가능하게 합니다. ALFWorld, VirtualHome, Minecraft, RLBench, 그리고 실제 로봇 시나리오에 대한 실험은 다양한 개방형 도메인 전반에 걸친 NESYC의 견고성과 적용 가능성을 입증합니다. 정적인 설정에서는 미리 정의된 전문가 지식 사용이 상충 관계를 수반함에도 불구하고, 제안된 모델은 여전히 다른 LLM 기반 및 신경-기호적 접근 방식보다 분명한 이점을 보여줍니다.

Llama-3-8B와 같은 더 작은 LLM에 적용될 때 어려움을 겪습니다. 규칙 재공식화 단계에서 지속적인 규칙 충돌 및 오류로 인해 성능 향상이 거의 달성되지 않습니다. 이에 더 작은 LLM을 사용한 자원 효율적인 구현 제어를 위해 신경-기호적 지식 증류 (neuro-symbolic knowledge distillation)를 탐색할 계획입니다.

---

### 참고 자료

[원본 경로 #1](https://arxiv.org/pdf/2503.00870)
