---
title: 'Generalized Class Discovery in Instance Segmentation'
date: '2025-04-16'
tags: ['computer vision', 'paper review']
---

### Abstract

This paper addresses generalized class discovery (GCD) in instance segmentation. The goal of this task is to discover new classes and obtain a model that can segment both labeled and unlabeled data using both types of data.

The real world contains numerous objects with long-tailed distributions, so the instance distribution of each class is inherently imbalanced. To address this, we propose instance-wise temperature assignment (ITA) for contrastive learning and class-wise confidence criteria for pseudo labels.

ITA relaxes instance identification for samples belonging to head classes to improve GCD. The confidence criterion is designed to prevent most pseudo labels for tail classes from being excluded when training networks using pseudo labels from GCD.

---

### Introduction

Supervised instance segmentation has achieved impressive performance but requires expensive manual labeling. To reduce annotation costs, researchers have studied semi-supervised learning that leverages unlabeled images along with small-scale labels, and weakly supervised learning that relies on weak labeling. However, all these methods rely on the closed world assumption and can only recognize known class objects.

To address this limitation, novel category discovery (NCD) was introduced, which, unlike SSL that assumes unlabeled images contain only known classes, assumes that unlabeled images contain new categories. Therefore, this method makes the problem more difficult and realistic.

GCD has been studied for balanced images, imbalanced scenarios, semantic segmentation, etc., and most utilize semi-supervised approaches and pseudo labels.

---

### Related works

#### 1. Generalized Class Discovery (GCD) in Image Classification

Vaze et al. (2022) introduced GCD by training networks using unsupervised contrastive learning on all data and supervised contrastive learning on labeled data. They then applied semi-supervised k-means clustering to assign class or cluster labels.

Zhang et al. (2023) published PromptCAL and used affinity graphs to generate pseudo labels for unlabeled data.

#### 2. Class Discovery in Segmentation and Detection

Zhao et al. (2022) introduced NCD in semantic segmentation and proposed using saliency models and segmentation networks trained on labeled data to find novel regions. Finally, they trained using labeled data and unlabeled images with clean pseudo labels obtained from clustering and online pseudo labels.

Fomenko et al. (2022) trained Faster R-CNN or Mask R-CNN using labeled data and froze the network except for the classification head. They then applied it to unlabeled and labeled images to obtain region proposals. Subsequently, they extended the classification head and trained using pseudo labels generated by clustering based on the Sinkhorn-Knopp algorithm.


---

### Method

We use a labeled dataset $D_l$ and an unlabeled dataset $D_u$. GCD in instance segmentation aims to discover new categories $C_n$ with $C_k \cap C_n = \varnothing$ and obtain a model that can segment instances of both known and new classes $C=C_k \cup C_n$.

Vaze et al. (2022) introduced contrastive learning and pre-trained the backbone using DINO on the ImageNet dataset without labels. They then fine-tuned the backbone and projection head using supervised CL on labeled data and unsupervised CL on both labeled and unlabeled data.

The GCD model $f_d(\cdots)$ consists of a backbone $b(\cdots)$ and a projection head $g(\cdots)$. We use an MLP for $g(\cdots)$ and a ResNet-50 backbone for $b(\cdots)$. During training, we use an encoder $f'_d(\cdots)$ whose parameters are a momentum-based moving average of the parameters of $f_d(\cdots)$.

The unsupervised contrastive loss $L^{u}_{rep}=-log \frac{exp(z_i^Tz_i'/{\tau})}{\sum_{z_j' \in \hat{Z_i'}} exp(z_i^Tz_j/{\tau})}$ and supervised contrastive loss $L^{s}_{rep} = \frac{1}{Z_i^P} \sum_{z'_k \in Z^P_i} log \frac{exp(z^T_i z'_k/{\tau})}{\sum_{z'_j \in \hat{Z'_i}} exp(z_i^Tz_k'/{\tau})}$ can be implemented, where $Z_i^P$ represents a subset of $Z'$ containing representations belonging to the same class as $I_i$, and $\tau$ is the temperature hyperparameter.

We first train an instance segmentation network $f_o(\cdot)$ to obtain class-agnostic instance masks for both known and unseen classes $C=C_k \cup C_n$. We train a class-agnostic instance segmentation network, the Generic Grouping Network (GGN) from Wang et al. (2022), using both $D_l$ and $D_u$.

Since $I^u_o$ and $I^l_o$ contain target objects along with background or adjacent objects, we studied a soft attention module (SAM) to encode object-specific features. We generate pseudo masks $M^u$ for $D_u$ using $f_o(\cdot)$, but directly using pseudo masks for encoding is risky due to noisy boundaries. Therefore, we trained the module using pseudo masks $M^u$ for $D_u$ and ground truth masks $M^l$ for $D_l$.

Zhang et al. (2021) implemented a KL divergence-based loss for unsupervised clustering on $I^u_o$ as $L^u_{cls}=\sum^C_{c=1} \bar{p_{ic}} log \frac{\bar{p_{ic}}}{q_{ic}}$, where $q_{ic}$ is the probability that $I_i$ belongs to class c. Additionally, we calculate the general cross-entropy loss $L^s_{cls}=\sum^C_{c=1} -y_{ic} log (q_{ic})$.

The total loss $L_{gcd}$ for $f_d(\cdot)$ is calculated as a weighted sum of two contrastive losses, two classification losses, and an attention loss as follows:

$$
L_{gcd} = L_{att} + (1-\lambda)L^u_{rep} + \\ \lambda L^s_{rep} + (1-\lambda) L^u_{cls} + \\ \lambda L^s_{cls}
$$

---

### Conclusion

This paper presents a novel GCD method in instance segmentation for open-world instance segmentation. To address the imbalanced distribution of instances, we introduce instance-wise temperature assignment and class-wise and dynamic confidence criteria. The former aims to improve the embedding space for class discovery, while the latter is designed to effectively utilize pseudo labels obtained from the GCD model. We also propose an efficient soft attention module. Experimental results in two settings demonstrate that the proposed method effectively discovers new classes and segments both known and novel category instances, showing superior performance compared to previous methods.

However, this study assumes that labeled and unlabeled datasets are completely available from the beginning. Therefore, it is not optimal for scenarios where data is provided sequentially, such as robot navigation. Additionally, following most previous studies, it assumes prior knowledge about the total number of classes.

---

### References

[Original Source #1](https://arxiv.org/pdf/2502.08149)
