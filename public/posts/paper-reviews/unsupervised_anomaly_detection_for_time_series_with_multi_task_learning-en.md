---
title: 'Unsupervised Anomaly Detection for Time Series Data of
Spacecraft Using Multi-Task Learning'
date: '2022-10-10'
tags: ['time-series', 'paper review']
---

### Abstract

In-orbit anomaly detection is crucial for ensuring spacecraft safety in orbit, but the complex spatial-temporal correlations in data and the sparsity of anomalies pose significant challenges.

This study proposes a new multi-task learning-based time series anomaly detection (MTAD) method that facilitates anomaly detection by capturing spatial-temporal correlations in data and learning generalized normal patterns. We implemented four proxy tasks to extract features through joint learning. The isolation forest algorithm detects anomalies from the extracted features.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/f6a7c136-f0e5-485a-b502-19a395ad72db/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:200;" />

In recent years, as the number of spacecraft in orbit has increased, the number of occasional spacecraft failures has also increased. Spacecraft constitute complex in-orbit systems, and failures of single components or subsystems can cause irreparable damage, especially if not detected in time. A reasonable approach for failure monitoring is to perform anomaly detection using the vast amount of telemetry data continuously generated by multiple spacecraft system components. This data constitutes multidimensional time series.

Spacecraft anomaly detection methods include out-of-limits, expert system-based, and data-driven methods. The complex spacecraft structure, tens of thousands of parameters, and spatial-temporal correlations between these parameters pose various difficulties for the aforementioned anomaly detection methods.

This study proposes a multi-task learning-based time series anomaly detection method (MTAD) that jointly trains a model on multiple different proxy tasks using high-dimensional and time series data from spacecraft.

---

### Related work

#### 1. Anomaly Detection

Existing autonomous spacecraft anomaly detection methods can be classified into three categories: model-based, signal processing-based, and knowledge-based methods.

Random forest algorithms have been utilized for anomaly detection of spacecraft rolling bearings based on the frequency of bearing fault signals. A model-based fault detection, isolation, and identification system has been proposed, which facilitates satellite attitude control subsystems by detecting and isolating faults in control moment gyros using unscented Kalman filters.

Deep learning methods can discover hidden patterns in data and do not rely on expert knowledge. In the context of spacecraft, recurrent neural network (RNN)-based methods have been developed to detect actuator failures in satellite attitude control systems. LSTM-based methods constitute common prediction-based approaches, and the anomaly detection effectiveness of these methods has been demonstrated using telemetry anomaly data labeled by experts from the Soil Moisture Active Passive satellite and the Mars Science Laboratory rover Curiosity.

#### 2. Multi-task learning

Multi-task learning applied in this study is a machine learning method based on shared representation that combines multiple related tasks to improve the model's generalization ability, thereby achieving superior overall performance compared to single-task learning. Unlike single-task learning, multi-task learning is used to learn multiple related tasks simultaneously in parallel and backpropagate gradients. Multi-task learning is a type of transfer learning that uses prior knowledge to help learn related or more complex tasks. This helps mitigate the data sparsity problem faced in the field of spacecraft anomaly detection.

#### 3. Deep learning models

RNN (Recurrent Neural Network) is a type of neural network with short-term memory capabilities. Neurons not only receive information from other neurons but can also form network structures containing loops using their own information. Using these self-feedback neurons, RNNs can process time series data of arbitrary length. However, when input sequences are relatively long, RNNs experience gradient explosion and vanishing gradient problems. Therefore, LSTM networks emerged as a variant to overcome these problems. Gates were introduced in LSTM networks to control information flow and temporal memory pathways.

TCN (Temporal Convolutional Network) is a convolutional neural network-based network that can be used to model time series data. TCN shows good performance when applied to time series data such as text and video, and has the advantage of low memory consumption for training. TCN integrates causal convolution, dilated convolution, and residual networks in addition to convolutional networks. Causal convolution establishes causal relationships between each layer of the network and is suitable for data containing temporal characteristics. Dilated convolution increases the receptive field while reducing network depth, and residual blocks within residual networks mitigate vanishing gradient problems using skip connections.

VAE (Variational Autoencoder) is a generative model based on Bayesian variational inference theory. The core concept is to model two complex conditional probability density functions using neural networks, through which latent variables $z$ are sampled from distribution $P(z)$ and data is generated through $P_\theta(x|z)$.

---

### Method

<img src="https://velog.velcdn.com/images/devjo/post/e94c8578-60cc-4954-be92-f52e8e527252/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:200;" />

$X_t = \{x_1, x_2, \cdots, x_M\} \in \mathbb{R}^M$ represents an $M$-dimensional data sample at time $t$, and $X$ is data acquired over multiple steps. The overall process of the MTAD method is shown in the image above and can be broadly divided into training and inference processes. First, training data is standardized and the mean $\mu_{train}$ and standard deviation $\delta_{train}$ are obtained. Subsequently, final input data $X$ and output $Y$ are obtained using a sliding window.

The multi-task model (MTADmt) simultaneously learns spatial-temporal patterns of spacecraft data through four proxy tasks described below.

1. Task 1 models temporal dependencies of time series data for prediction using an LSTM network. The input is an $M \times K$ matrix, and the output is $o_{Task1} \in \mathbb{R}^M$, which is a prediction for the next $P$ steps. The LSTM loss is derived using MSE determined from the difference between actual and predicted values.

2. Task 2 uses a temporal convolutional AE neural network to generate latent representations based on spatial patterns in data and reconstruct the data. AE learns latent representations of data in an unsupervised manner. For an $M$-dimensional data sample $X^i \in \mathbb{R}^M$, it reduces to $k$ dimensions, where the compressed representation of dimension $i$ is $Z^i$. The error is derived from the difference between the reconstructed values of the AE network and the actual values $X$, and is calculated using the logcosh function.

3. Task 3 uses an LSTM VAE neural network to generate latent representations and reconstruct inputs to model spatial patterns in data. VAE models conditional probability density functions using inference and generation networks. The probabilistic encoder models latent variable distributions, and since it considers latent space variability during sampling, VAE has higher representational capacity than AE. Therefore, building on Task 2, Task 3 is designed to learn VAE-based latent representations and reconstruct data to improve the model's spatial dependency capture performance.

4. Task 4 outputs predictions from joint latent representations learned in Tasks 2 and 3 using an LSTM network. Here, $z_{input}$ is the input for Task 4, where $z_{input} = [z_{ae}, z_{vae}]$.

Based on the multi-task model (MTADmt), features of X are extracted as $Err(X) = [Err_1(X), Err_2(X), Err_3(X), Err_4(X)]$, where $Err_i(X)$ is the loss of proxy task $i$ for input $X$. An iForest (isolation forest)-based error evaluation and anomaly detection model (MTADad) is trained to perform anomaly detection from $Err(X)$. Random hyperplanes repeatedly cut the data space into two subspecies and continue until no further subdivision is possible. Thus, isolated trees are formed where each leaf node contains only one data sample.

---

### Conclusion

In this study, we proposed a new multi-task learning-based unsupervised anomaly detection technique called MTAD (Multi-task learning-based Time series Anomaly Detection).

We implement an iForest-based model to capture spatial-temporal correlations in multidimensional time series data obtained from spacecraft, extract anomaly features, and detect anomalies from those features.

In future research, we will evaluate our model on more real-world datasets with different characteristics, such as data from various satellite subsystems, different anomaly ratios, and various types of spacecraft data. Additionally, we will investigate the impact of assigning weights to multiple proxy tasks on model performance. Overall, the results of this study demonstrate the promising potential of the proposed MTAD technology for in-orbit spacecraft anomaly detection.

---

### References

[Original Source #1](https://www.mdpi.com/2076-3417/12/13/6296)
