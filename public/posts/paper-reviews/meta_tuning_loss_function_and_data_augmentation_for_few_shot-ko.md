---
title: 'Meta-tuning Loss Functions and Data Augmentation for Few-shot Object Detection'
date: '2025-05-17'
tags: ['robotics', 'paper review']
---

### Abstract

극소수 객체 탐지(FSOD)는 적은 수의 훈련 인스턴스로 새로운 객체 탐지 범주를 모델링하는 문제로, 극소수 학습(few-shot learning) 및 객체 탐지 분야에서 떠오르는 주제입니다. 현대 기술들은 크게 두 그룹으로 나눌 수 있습니다: 미세 조정 기반(fine-tuning based) 접근법과 메타 학습 기반(meta-learning based) 접근법입니다.

메타 학습 접근법은 새로운 클래스 모델에 샘플을 매핑하기 위한 전용 메타 모델을 학습하는 것을 목표로 하는 반면, 미세 조정 접근법은 경사 기반 최적화를 통해 탐지 모델을 새로운 클래스에 적응시킴으로써 더 간단한 방식으로 극소수 탐지를 해결합니다. 그 단순성에도 불구하고, 미세 조정 기반 접근법은 일반적으로 경쟁력 있는 탐지 결과를 산출합니다.

이러한 관찰을 바탕으로, 이 연구는 미세 조정 프로세스를 주도하는 힘으로서 손실 함수(loss functions)와 데이터 증강(augmentations)의 역할에 초점을 맞추고, 메타 학습 원리를 통해 그들의 동역학을 조정할 것을 제안합니다. 따라서, 제안된 훈련 방식은 미세 조정 기반 접근법의 장점을 유지하면서 극소수 탐지를 향상시킬 수 있는 귀납적 편향(inductive biases)을 학습할 수 있게 합니다.

또한, 제안된 접근법은 매우 많은 매개변수와 복잡성을 가진 극소수 메타 모델과 달리, 해석 가능한 손실 함수를 제공합니다. 실험 결과는 표준 및 일반화된 극소수 성능 지표 모두에서 벤치마크인 Pascal VOC와 MS-COCO 데이터셋의 강력한 미세 조정 기반 극소수 탐지 기준선에 비해 상당한 개선을 보여주며, 제안된 방식의 장점을 강조합니다.

---

### Introduction

FSOD는 대규모 훈련 데이터가 있는 기본 클래스(base classes)의 지식을 활용하여, 레이블이 적은 이미지 몇 장만으로 새로운 클래스(novel classes)에 대한 탐지 모델을 구축하는 것을 목표로 합니다. 이와 관련된 일반화 극소수 객체 탐지(G-FSOD)는 기본 클래스와 새로운 클래스 모두에서 잘 작동하는 모델을 만드는 것을 목표로 합니다.

FSOD를 해결하는 방법은 크게 두 가지로 나뉩니다.

메타 학습(Meta-learning) 기반 접근법: 소수의 훈련 샘플을 새로운 클래스 탐지 모델로 매핑하는 전용 메타 모델을 설계하고 훈련하는 방식입니다. 하지만 이 방식은 모델 복잡성으로 인해 기본 클래스에 과적합될 위험이 있고, 무엇을 학습했는지 해석하기 어렵다는 중요한 단점이 있습니다.

미세 조정(Fine-tuning) 기반 접근법: 일반적인 전이 학습(transfer learning) 문제로 접근하여, 사전 훈련된 모델을 경사 기반 최적화를 통해 새로운 클래스에 맞게 조정하는 방식입니다. 단순하고 일반적이지만, 메타 학습 기반 접근법에 비해 경쟁력 있는 결과를 내는 경우가 많습니다.

논문은 미세 조정 기반 FSOD의 가장 큰 장점이자 단점인 '일반성(generality)'에 주목합니다. 일반성은 소수의 샘플로 효과적으로 학습하는 데 필요한 귀납적 편향(inductive biases)이 부족할 수 있습니다.

이를 해결하기 위해, 논문은 미세 조정 단계에서 사용되는 손실 함수와 데이터 증강(augmentations)을 메타 학습 원리를 적용하여 조정하는 '메타 튜닝(meta-tuning)' 방식을 제안합니다. 이 방식은 다음과 같은 특징을 가집니다.


데이터 기반 학습: 에피소드(episodic) 훈련 절차를 통해 FSOD에 최적인 손실 함수와 증강 기법을 점진적으로 발견합니다.


강화 학습(RL) 활용: 강화 학습 기술을 사용하여 손실 함수와 증강 기법을 조정함으로써, 미세 조정을 통해 얻은 FSOD 모델의 예상 탐지 품질을 극대화합니다.


해석 가능성: 복잡한 메타 모델과 달리, 메타 튜닝을 통해 학습된 매개변수는 해석 가능한 손실 함수를 산출합니다.


효과적인 귀납적 편향 주입: 학습된 손실 함수와 증강 기법이 FSOD에 특화된 귀납적 편향을 미세 조정 기반 접근법에 주입합니다.

---

### Related work

#### 1. Few shot classification

극소수 학습(FSL)을 위한 대부분의 메타 학습 접근법은 적응 기반(adaptation-based) 방식과 매핑 기반(mapping-based) 방식으로 나눌 수 있습니다.

적응 기반 (경사 기반) 접근법: 몇 번의 모델 업데이트 단계 내에서 새로운 미지의 극소수 작업에 쉽게 적응할 수 있는 모델 매개변수를 학습하는 것을 목표로 합니다.

매핑 기반 (메트릭 기반) 접근법: 경사 하강 기반의 적응 단계를 건너뛰고, 대신 데이터-분류기 매핑을 학습하는 것을 목표로 합니다.

이 외에도 새로운 클래스를 위한 합성 데이터를 생성하거나, 더 나은 특징 표현을 사용하거나, 미분 가능한 볼록 솔버(differentiable convex solvers)를 활용하는 등의 주목할 만한 접근법들이 있습니다. 중요한 것은, 세심하게 훈련된 표현과 간단한 미세 조정 또는 얕은 분류기만으로도 메타 학습 기반 접근법보다 경쟁력 있거나 더 나은 성능을 낼 수 있다는 점을 여러 연구들이 강조하고 있다는 것입니다.

#### 2. Few shot object detection

FSOD 접근법은 메타 학습 기반과 미세 조정(전이 학습) 기반으로 요약할 수 있습니다. 대부분의 메타 학습 기반 FSOD 접근법은 FSL의 매핑 기반 메타 학습 접근법에서 사용되는 것과 유사한 공식을 채택합니다. 지원 특징 집합(Support feature aggregation)은 메타 학습 기반 방법들이 서로 다른 주요 측면 중 하나입니다.

메타 학습 기반 FSOD를 개선하기 위한 최근의 노력에는 주로 손실 함수, 특징 매칭, 새로운 클래스 샘플 사용 효율성 향상을 위한 보완 기술들이 포함됩니다.

손실 함수: 클래스 마진 손실, 마진 기반 순위 손실, 초점 손실(focal loss), 적응형 마진 손실 및 대비 손실(contrastive loss)로 구성된 하이브리드 손실 등 다양한 손실 함수가 사용됩니다.

특징 매칭: 질의 이미지와 지원 이미지 사이의 특징을 매칭하여 지원 이미지의 정보를 더 효과적으로 사용합니다.

샘플 증강: 가우시안 노이즈를 추가하여 새로운 클래스 샘플을 증강하기도 합니다.

미세 조정 기반 방법들은 일반적으로 사전 훈련된 탐지 네트워크의 일부를 고정하고, 보조 탐지 헤드를 추가하며, 새로운 클래스 분산을 증가시킨 다음, 경사 하강 기반의 모델 업데이트 단계를 적용합니다. 이는 복잡한 에피소드 학습을 사용하는 메타 학습 기반 방법과는 다릅니다.

Wang et al.: Faster-RCNN을 기반으로, 미세 조정 중 클래스에 구애받지 않는 영역 제안 네트워크(RPN) 구성 요소를 고정하는 접근법을 제안했습니다.

Sun et al.: FPN 및 RPN 레이어를 학습 가능한 매개변수 집합에 포함하여 새로운 객체의 보다 정확한 분류를 촉진하는 대비 제안 인코딩(contrastive proposal encodings)을 사용합니다.

Wu et al.: 지원 세트의 스케일 분포가 불균형하다는 것을 보여주며, 주 모델에 추가로 다중 스케일 양성 샘플 정제(MPSR) 브랜치를 제안했습니다.

Fan et al.: 기본 클래스에 대한 미세 조정 중 망각을 방지하기 위해 Retentive R-CNN 아키텍처를 제안했습니다.

#### 3. Automated loss function discovery

손실 함수 발견은 AutoML 분야에서 떠오르는 주제로, 데이터 기반으로 학습 시스템을 개선하는 것을 목표로 합니다. 기존 방법들은 크게 두 가지로 나뉩니다.

손실 함수 직접 구성: 기본 연산자들을 조합하여 손실 함수를 만드는 방식입니다. 유전 알고리즘을 사용해 손실 함수의 유효성을 검증하고 품질을 필터링하는 모듈을 제안하는 연구, 수학적 연산으로 구성된 트리에서 후보 손실 함수를 선택하고, 성공적인 함수를 다음 단계로 돌연변이(mutate)시키는 유전 알고리즘을 사용하는 연구가 있습니다.

매개변수화된 손실 함수 최적화: 기존 손실 함수를 재분석하여 결합된 공식으로 제시하거나, 탐색 공간을 단순화하는 방식으로 최적화하는 방식입니다.

이러한 연구들은 주로 지도 학습 시나리오를 대상으로 하지만, 이 논문은 손실 함수 학습 원리를 극소수 객체 탐지(FSOD) 문제에 적용하는 것을 목표로 합니다.

#### 4. AutoML for data augmentation

최근에는 다양한 자동화된 데이터 증강 기법이 제안되었습니다.

강화 학습 기반: 강화 학습과 순환 신경망(RNN) 컨트롤러를 사용하여 최적의 증강 정책을 생성합니다.

비용 절감: 개체군 기반 프레임워크를, 베이시안(Bayesian) 방법을 사용하여 계산 비용을 줄입니다.

공유된 매개변수: 최적의 증강 크기(magnitude)가 변환 전반에 걸쳐 유사한 경향이 있으며, 공유된 값을 사용해 탐색 과정을 크게 단순화할 수 있음을 보여줍니다. 이 논문도 이러한 제안을 따라 모든 변환에 걸쳐 공유된 크기를 사용합니다.

이러한 연구들이 주로 지도 학습에 초점을 맞추는 것과 달리, 이 논문은 적은 수의 샘플로 탐지기를 학습하는 문제에 집중합니다.

---

### Method

이 논문은 소수점 객체 감지(FSOD) 문제를 다룹니다. 이 설정에서는 모델이 "기본(base)" 클래스에 대한 대규모 데이터셋으로 훈련된 다음, "새로운(novel)" 클래스에 대해 소수의 훈련 예제(k-shot)만으로 객체를 감지해야 합니다.

기본 모델로는 MPSR FSOD 방법이 사용됩니다. 이는 Faster R-CNN을 미세 조정(fine-tuning) 기반 FSOD에 맞게 조정한 것입니다. MPSR은 스케일 희소성(scale sparsity) 문제를 해결하기 위해 보조적인 다중 스케일 긍정 샘플 개선(multi-scale positive sample refinement) 분기를 사용합니다. 이 분기는 객체의 크기 분포가 제한적인 문제를 해결하기 위해, 부적절한 부정 사례를 늘리지 않으면서 긍정 샘플의 스케일 공간을 확장합니다. 이는 데이터 분포를 변경하지 않는 특징 피라미드 네트워크나 이미지 피라미드와는 다릅니다.

#### 1. Meta-tuning loss functions

기본 MPSR 모델의 분류 손실 항은 다음과 같이 표현됩니다.

$$
L_{cls}(x,y) = -\frac{1}{N_{ROI}} \sum_{i}^{N_{ROI}} log (\frac{e^{f(x_i, y_i)}}{\sum_y e^{f(x_i, y)}})
$$

여기서 $N_{ROI}$는 이미지 내 관심 영역의 수이고 $y_i$는 $i$번째 실제 클래스 레이블입니다. 저자들은 손실 함수에 더 많은 유연성을 주기 위해서 매개변수 함수를 $L_{cls}(x,y;\rho)$로 재정의합니다.

$$
L_{cls}(x,y;\rho) = -\frac{1}{N_{ROI}} \sum_{i}^{N_{ROI}} log (\frac{e^{f(x_i, y_i)/{\rho_{\tau}}}}{\sum_y e^{f(x_i, y')/{\rho_{\tau}}}})
$$

#### 2. Meta-tuning procedure

일반화 능력을 극대화하기 위해 새로운(novel) 클래스 대신 기본(base) 클래스로 프록시 작업을 생성하여 모방합니다. 이 과정은 아래와 같습니다.

클래스 분할 : 기본 클래스 $C_b$를 두 개의 부분 집합인 프록시 기본 $C_{p-base}$와 프록시 소수 $C_{p-novel}$로 나눕니다.

기본 클래스 분할 : 세 개의 겹치지 않는 부분으로 나눕니다. $D_{p-pretrain}$는 프록시 기본 클래스만을 가지고 메타 튜닝을 위한 임시 객체 감지 모델을 훈련하는데 사용합니다. $D_{p-support}$는 프록시 기본과 소수를 모두 포함하며 미세 조정용 이미지로 사용합니다. 마지막으로 $D_{p-query}$는 역시 프록시 기본과 소수를 모두 포함하지만 미세 조정된 모델의 성능 평가용 이미지로 사용합니다.

---

### Conclusion

기존 fine-tuning 기반 FSOD 모델의 주요 한계는 소수점 훈련을 위한 미세 조정 세부 사항을 수작업으로 설계하는 데 중점을 둔다는 점입니다. 이는 본질적으로 어려울 뿐만 아니라 최적의 결과를 얻지 못할 가능성이 높습니다.

이러한 한계를 해결하기 위해, 메타-학습(meta-learning)을 통해 미세 조정 기반 학습 동학(learning dynamics)을 배우는 것을 제안합니다. 이를 통해 소수점 학습에 필요한 귀납적 편향(inductive biases)을 학습할 수 있습니다.

본 논문이 제안하는 튜닝 방식은 강화 학습(reinforcement learning)과 메타-학습 원리를 결합하여, 소수점 훈련을 위한 해석 가능한(interpretable) 손실 함수와 증강(augmentation) 크기를 얻습니다. Pascal VOC 및 MS COCO 데이터셋에 대한 광범위한 실험 결과는 제안된 메타-튜닝(meta-tuning) 접근법이 FSOD와 G-FSOD 설정 모두에서 강력한 fine-tuning 기반 소수점 감지 기준 모델들보다 일관되게 상당한 성능 향상을 제공함을 보여줍니다.

---

### 참고 자료

[원본 경로 #1](https://arxiv.org/pdf/2304.12161)
