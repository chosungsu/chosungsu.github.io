---
title: 'ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning'
date: '2025-10-04'
tags: ['embodied ai', 'paper review']
---

### Abstract

시각-언어-행동 (Vision-language-action, VLA) 추론 작업은 에이전트가 멀티모달 명령을 해석하고, 장기 계획을 수행하며, 동적 환경에서 적응적으로 행동하도록 요구합니다. 기존 접근 방식들은 일반적으로 VLA 모델을 종단 간 방식 (end-to-end)으로 훈련시켜 입력을 명시적인 추론 없이 행동에 직접 매핑하는데, 이는 다단계에 걸쳐 계획하거나 복잡한 작업 변형에 적응하는 능력을 저해합니다.

본 논문에서 강화된 시각 잠재 계획 (reinforced visual latent planning)을 통해 고수준 추론과 저수준 행동 실행을 연결하는 이중 시스템 프레임워크인 ThinkAct를 제안합니다.

ThinkAct는 목표 완료와 궤적 일관성을 기반으로 행동 정렬 시각 보상을 강화함으로써 안내되는 체화된 추론 계획을 생성하도록 멀티모달 LLM을 훈련시킵니다. 이러한 추론 계획은 시각 계획 잠재 벡터 (visual plan latent)로 압축되어, 대상 환경에서 강건한 행동 실행을 위한 다운스트림 행동 모델을 조건화합니다.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/f8424868-ee01-4364-9db2-c4ef8436384f/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:200;" />

멀티모달 대규모 언어 모델 (MLLMs)의 최근 발전은 시각적 질문 답변 및 이미지/비디오 캡셔닝과 같이 멀티모달 입력의 이해를 요구하는 다양한 작업에서 인상적인 진전을 가져왔습니다. 그러나 멀티모달 콘텐츠가 이제 효과적으로 인지되고 해석될 수 있지만, 장기 사용자 목표를 위한 다단계 계획을 수행하고 동적 환경과 상호 작용하는 것은 최첨단 MLLMs에게 여전히 도전으로 남아있습니다.

VLA에 복잡한 체화된 작업을 해결할 수 있는 능력을 부여하기 위해, 최근 연구는 중간 단계별 지침으로서 명시적인 사고의 연쇄 (Chain-of-Thought, CoT) 프롬프트를 통합하는 것을 탐구했습니다. 예를 들어, ECoT와 RAD는 즉시 사용 가능한 MLLMs에 프롬프트를 제공하여 중간 단계 및 분해된 계획을 생성하는 데이터 큐레이션 파이프라인을 도입합니다. 주석이 달린 CoT 추적이 확보되면, VLA는 완전 지도 미세 조정 (SFT)을 통해 중간 단계를 예측하도록 훈련됩니다. 그러나 고품질 추론 추적을 생성하는 높은 비용으로 인해, 결과 모델은 특정 시각 장면이나 추론 패턴에 과적합되기 쉽습니다.

강화 학습은 은 완전 지도 CoT 주석에만 의존하는 대신 보상 신호를 극대화하는 사고 추적을 탐색함으로써 LLMs의 추론 행동을 장려할 상당한 잠재력을 보여주었습니다.

---

### Methods

<img src="https://velog.velcdn.com/images/devjo/post/a3e6d818-50c6-4ff2-b635-11058a22b65b/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:200;" />

시각-언어-행동 (VLA) 추론 작업에 대한 설정과 표기법을 정의합니다. 각 시간 단계 $t$에서 모델은 시각 관찰 $o_t$와 텍스트 명령 $l$을 받으며, 목표는 행동 $a_t$를 예측하는 것입니다. $a_t$는 체화에 따라 텍스트 명령어일 수도 있고 7-자유도 (DOF) 제어 벡터 $[\Delta x, \Delta \theta, \Delta \text{Grip}]$일 수도 있습니다.

이 문제를 해결하기 위해, 통합 프레임워크인 ThinkAct를 제안합니다. 이는 MLLM $\mathcal{F}_\theta$를 활용하여 고수준 계획을 추론하는 동시에 행동 모델 $\pi_\varphi$와 연결하여 실행 가능한 행동을 추론하는 것을 목표로 합니다. MLLM $\mathcal{F}_\theta$는 $(o_t, l)$을 기반으로 시각 계획 잠재 벡터 $c_t$를 생성하며, 이는 고수준 의도와 계획 맥락을 포착합니다.

#### 체화된 추론을 위한 강화된 시각 잠재 계획

다양한 환경에 걸쳐 일반화되는 체화된 추론을 가능하게 하기 위해, 강화 학습을 통해 멀티모달 LLMs의 추론 능력을 장려하는 것을 목표로 합니다. 직관적인 방법은 MLLM이 저수준 행동을 생성하기 전에 추론하도록 하고, 그 결과로 발생하는 대상 환경에서의 작업 성공률 (예: LIBERO)을 보상 신호로 사용하는 것입니다. 그러나 이 접근 방식은 시각 장면으로부터의 적절한 안내 없이 특정 시뮬레이터에 국한됩니다.

이러한 도전을 해결하기 위해 장기 목표를 포착하고 계획 중 시각적 접지를 장려하는 새로운 행동 정렬 시각 피드백을 설계합니다. 구체적으로 그리퍼 말단 장치를 시각 장면 위에 포착하는 시공간 궤적으로 고수준 계획을 표현할 수 있으며, 이는 체화된 추론을 유도하는 시각-행동 안내 역할을 합니다.

시간 단계 $t$에서의 관찰 $o_t$와 작업 명령 $l$이 주어졌을 때, MLLM $\mathcal{F}_\theta$는 추론을 위한 잠재 임베딩 시퀀스 $v_t \in \mathbb{R}^{|v_t| \times d}$와 시각 계획 잠재 벡터 $c_t \in \mathbb{R}^{|c_t| \times d}$를 자기회귀적으로 생성합니다. 전자는 추론 단계로 디코딩되는 반면, 후자는 $p_k \in [0, 1]^2$인 $\text{2D}$ 포인트의 텍스트 문자열 $\tau = [p_k]^K_{k=1}$로 추론됩니다. 여기서 $p_1$과 $p_K$는 그리퍼의 시작 및 끝 위치를 나타냅니다.

$$
r_{\text{goal}} = \frac{1}{2} (f(p_1, \hat{p}_1) + f(p_K, \hat{p}_K))
$$

예측된 시작 및 끝 위치를 오프더-쉘프 검출기에 의해 얻어진 궤적 $\hat{\tau} = [\hat{p}_k]^K_{k=1}$의 해당 포인트와 비교하기 위한 목표 보상 $r_{\text{goal}}$을 도입합니다.

#### 추론 강화 행동 적응

MLLM이 추론한 고수준 체화 의도를 통해, 추론된 시각 잠재 계획 $c_t$를 행동 모델 $\pi_\varphi$와 행동하기 전에 생각하는 방식으로 연결하여 체화된 추론을 실행 가능한 행동과 함께 물리적 세계에 접지하는 것입니다.

$$
\mathcal{L}_{\text{IL}}(\varphi) = \mathbb{E}_{(o_i, l, a_i)} \left[ \ell \left( \pi_\varphi(c_t, o_i, l), a_i \right) \right]
$$

구체적으로, 시각 관찰 및 언어 명령으로 구성된 현재 상태를 기반으로 행동을 예측하는 트랜스포머 기반 행동 모델 $\pi_\varphi$ (예: 확산 정책 (Diffusion Policy))를 기반으로 구축합니다. $\pi_\varphi$는 인지만을 사용하여 대상 환경에서 작동할 수 있지만, 고수준 체화 의도 및 계획 맥락을 인코딩하는 잠재 계획 $c_t$를 조건으로 함으로써 그 능력을 향상시킵니다. 주석이 달린 행동 시연을 사용하여 모방 학습을 통해 상태 인코더, 잠재 프로젝터, 및 행동 모델만을 업데이트합니다.

---

### Conclusion

시각-언어-행동 추론 작업을 위해 강화된 시각 잠재 계획을 사용하는 프레임워크인 ThinkAct를 제시했습니다. 행동 정렬 강화 학습과 추론 강화 행동 적응을 결합함으로써, ThinkAct는 체화된 에이전트가 행동하기 전에 생각하고 동적 환경에서 강건한 행동을 실행할 수 있도록 합니다. 체화된 추론 및 로봇 조작 벤치마크에 대한 광범위한 실험을 통해, 강력한 장기 계획, 소수샷 적응, 그리고 실패 감지 및 자체 수정과 같은 창발적 행동을 입증했으며, 이는 더 숙고적이고 적응 가능한 체화된 AI 시스템을 향한 확장 가능한 경로를 제공합니다.

ThinkAct는 사전 훈련된 멀티모달 LLMs를 기반으로 구축되므로, 특히 시각적 또는 공간적 추론에서의 환각 (hallucinations)과 같은 그들의 한계를 피할 수 없이 물려받습니다. 이는 잘못된 객체 속성이나 공간적 관계를 참조하는 계획으로 이어질 수 있으며, 다운스트림 실행에 영향을 미칩니다. 제안된 모델의 잠재 계획 및 행동 접지가 이를 어느 정도 완화하지만, MLLMs에서 접지 인식 훈련 또는 환각 억제에 대한 향후 연구는 실제 배포에서 강건성과 신뢰성을 더욱 향상시킬 수 있습니다.

---

### 참고 자료

[원본 경로 #1](https://arxiv.org/pdf/2507.16815?)
