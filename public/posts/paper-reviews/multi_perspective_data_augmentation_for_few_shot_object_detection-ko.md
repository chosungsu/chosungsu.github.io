---
title: 'Multi-Perspective Data Augmentation for Few shot object detection'
date: '2025-04-30'
tags: ['computer vision', 'paper review']
---

### Abstract

최근 소수 샷 객체 탐지 연구는 새로운 클래스(novel class)를 위한 합성 샘플을 생성하는 데 집중하고 있으며, 특히 확산 모델을 활용한 성과가 두드러집니다. 하지만 이러한 합성 데이터셋은 전경(Foreground)과 배경(Background)의 관계를 충분히 고려하지 못해 전형적인 샘플(typical samples)과 어려운 샘플(hard samples)을 생성하는 다양성 측면에서 한계를 보입니다.

본 논문에서는 이러한 한계를 극복하기 위해 세 가지 핵심 전략을 포함하는 MPAD 프레임워크를 제안합니다. 인컨텍스트 학습을 객체 합성에 도입하고 바운딩 박스 조정을 병행합니다. 이는 합성된 샘플의 세부 묘사와 공간적 정보를 강화할 수 있습니다. 다음으로 확산 모델의 생성 과정 중 각 타임스텝에서 프롬프트 임베딩을 혼합합니다. Large margin 원칙에 따라 support sample이 클래스 경계를 정의하는 데 핵심적인 역할을 하도록 유도하여 어려운 samples를 생성합니다. 마지막으로 전형적이거나 학습하기 까다로운 배경을 샘플링하는 배경 제안 방법을 도입합니다.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/7296fec1-d627-4290-a205-31940eccbcbb/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

사람은 단 몇 번의 노출만으로도 새로운 사물을 인식할 수 있습니다. 이를 모방하는 소수 샷 객체 탐지(FSOD)는 두 가지 데이터셋을 기반으로 합니다. base는 수많은 클래스와 풍부한 훈련 샘플을 포함하며, 탐지 작업을 위한 일반적인 지식을 형성합니다. novel은 클래스당 샘플이 매우 제한적(소수 샷)이며, 모델 학습에 큰 도전 과제가 됩니다.

LLM의 일반 지식을 활용하여 새로운 클래스의 세부 속성을 탐색하고 프롬프트를 다양화합니다. 이는 전형적인 샘플뿐만 아니라 어려운 샘플(hard samples)까지 생성할 수 있게 합니다. 확산 모델의 생성 타임스텝마다 프롬프트 임베딩을 혼합하여, 메인 클래스의 특징과 베이스 클래스의 저수준 특징(모양, 색상 등)이 섞인 '하드 샘플'을 생성합니다.

---

### Methods

#### In-Context learning for object synthesis

<img src="https://velog.velcdn.com/images/devjo/post/a166ccb4-f636-4d1f-9c6b-234b97545a28/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

단순히 이미지를 생성하는 것이 아니라, 기존 이미지의 특정 위치에 객체를 자연스럽게 그려 넣기 위해 PowerPaint 모델을 사용한 인페인팅(Inpainting) 기술을 활용합니다. 객체의 바운딩 박스($b$)에 마스킹과 패딩을 적용하여 확산 모델이 그림을 그려야 할 영역을 지정합니다.

역확산(denoising)은 아래 수식과 같이 노이즈($z_t$)에서 시작하여 프롬프트 임베딩($\zeta_c$)과 바운딩 박스($b$) 조건에 맞춰 점진적으로 선명한 객체를 만들어냅니다.

$$
z_{t-1} = p(z_{t-1}|\theta(z_t, \zeta_c, b))
$$

기존 연구들은 "a photo of a [클래스 이름]"과 같은 매우 단순한 프롬프트를 사용했습니다. 하지만 이는 생성된 객체들이 모두 비슷한 모습(전형적인 샘플)으로 나타나는 다양성 부족의 문제와 색상, 모양, 재질 등 객체를 구분 짓는 중요한 특징들이 무시되는 세부 정보 결여의 문제를 보입니다.

이 문제를 해결하기 위해 LLM의 일반 지식을 프롬프트 생성에 활용하는 인컨텍스트 학습(In-Context Learning)을 도입합니다. 특정 클래스의 외형 정보를 묻고 이를 딕셔너리 형태로 파싱합니다. 예를 들어 "새(bird)"라는 클래스라면 "노란 부리, 푸른 날개, 작은 발"과 같은 상세 정보를 프롬프트에 추가하여 확산 모델이 더 정교한 이미지를 그리도록 유도합니다. 클래스의 일반적인 이름 대신 구체적인 종이나 유형을 나열하여 데이터의 폭을 넓힙니다. 이로써 모델이 "새"라는 상위 개념 안에서 발생할 수 있는 수많은 변이(Variation)를 학습할 수 있게 되어 일반화 성능이 크게 향상됩니다.

#### Harmonic prompt aggregation scheduler

단일 클래스 정보만 사용하는 대신, 베이스 클래스($\zeta_{base}$)와 새로운 클래스($\zeta_c$)의 임베딩을 생성 공정의 각 단계($t$)에서 혼합합니다.

$$
\gamma_{c,t} = (1 - \alpha_t) * \zeta_c + \alpha_t * \zeta_{base}
$$

생성 초기 단계에서는 베이스 클래스의 가중치를 높여 전체적인 형태와 구조(Low-level features)를 잡고, 생성 후기 단계로 갈수록 새로운 클래스의 가중치를 높여 세부적인 특징(High-level details)을 입힙니다.

#### Background proposal method

사전 학습된 ViT 모델을 사용해 합성된 새로운 객체($\hat{I}_c$)와 베이스 이미지 배경 간의 코사인 유사도(Cosine Similarity)를 측정합니다. 유사도가 높은 상위 배경을 선택하여 합성에 사용합니다.

---

### Conclusion

확산 모델을 이용한 데이터 증강은 매우 강력하지만, 본 연구에서도 몇 가지 해결해야 할 과제가 확인되었습니다. 생성된 객체의 일부 또는 전체가 프롬프트와 무관하게 나타나거나 저품질로 생성되는 Hallucination 현상이 발생합니다.

이를 해결하기 위한 생성 후 일반적인 특징에서 크게 벗어난 객체를 걸러내는 사후 필터링 프로세스 적용 방안이나 LoRA와 같은 효율적인 미세 조정 기법을 사용해 확산 모델을 소수 샷 데이터에 직접 최적화하여 데이터 유사성을 높이는 방안을 고려할 수 있습니다.

---

### 참고 자료

[원본 경로 #1](https://arxiv.org/pdf/2502.18195)
