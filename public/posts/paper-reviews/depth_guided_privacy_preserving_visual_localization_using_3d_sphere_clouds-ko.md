---
title: 'Depth-Guided Privacy-Preserving Visual Localization Using 3D Sphere Clouds'
date: '2025-05-03'
tags: ['3d perception', 'paper review']
---

### Abstract

희소 3차원 포인트 클라우드로부터 고충실도 장면 세부 정보를 드러낼 수 있는 딥 신경망의 출현은 개인 지도와 관련된 시각적 측위에서 상당한 개인 정보 보호 문제를 제기했습니다.

지도 포인트를 무작위로 방향이 지정된 3차원 선으로 끌어올리는 것 (lifting)은 장면 이미지의 원치 않는 복구를 방해하는 잘 알려진 접근 방식이지만, 이러한 선은 선의 이웃 통계를 관찰하여 포인트 클라우드 기하학을 복구할 수 있는 밀도 기반 공격에 취약합니다.

이 공격을 무력화하는 것을 목표로 모든 포인트를 지도의 도심 (centroid)을 가로지르는 3차원 선으로 끌어올려 단위 구의 포인트와 유사하게 구성된 구름 (sphere cloud)이라고 불리는 새로운 개인 정보 보호 장면 표현을 제시합니다. 선은 지도 도심에서 가장 밀도가 높기 때문에, 구름은 밀도 기반 공격 알고리즘을 오도하여 도심에서 포인트를 잘못 생성하도록 함으로써 공격을 효과적으로 무력화합니다.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/5f04b39f-a3c8-4a22-8fb1-c53adb85b34b/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:200;" />

시각적 측위는 입력 이미지로부터 6-DOF 카메라 포즈를 추정하는 작업을 의미하며 자율 주행, 확장 현실 및 로봇 공학에서 핵심적인 계산입니다.

포인트 클라우드와 디스크립터는 클라우드 기반 측위를 위해 서버에 저장되거나 실시간 측위를 위해 클라이언트에 배포됩니다.

#### 개인 정보 보호 문제와 기존 방어의 취약성

최근까지 종종 개인이거나 기밀 영역/객체를 포함할 수 있는 이러한 포인트 지도는 호기심 많은 침입자나 악의적인 클라이언트가 3차원 포인트에서 장면 세부 정보를 드러내려는 시도를 단념시키기에 충분히 희소한 것으로 인식되었습니다.

그럼에도 불구하고, Pittaluga et al.의 InvSfM 작업은 희소 포인트 클라우드에서 고충실도 장면 이미지를 복구할 가능성을 보여주었으며, 측위를 위해 맨몸의 포인트 지도를 사용할 때 상당한 개인 정보 보호 문제를 제기했습니다.

현재 이 문제를 완화하기 위한 가장 널리 알려진 접근 방식 중 하나는 각 포인트를 3차원 선으로 끌어올려 포인트 위치를 숨기고 InvSfM을 사용한 직접적인 이미지 합성을 비활성화하는 선 클라우드로 포인트 지도를 숨기는 것입니다.

불행히도, 이러한 일련의 작업은 선의 이웃 통계를 사용하여 3차원 선을 포인트로 효과적으로 되돌릴 수 있는 밀도 기반 공격에 잠재적으로 취약합니다.

#### Sphere Cloud 제안과 당면 과제

본 연구에서 우리는 앞서 언급된 기하학 복원 공격을 무력화하기 위한 노력으로 sphere cloud로 불리는 새로운 개인 정보 보호 장면 표현을 제시합니다.

단순히 포인트 클라우드의 중심을 통과하는 3차원 선으로 포인트를 끌어올려 구성된 구름은 이웃 선 통계가 퇴화된 포인트 복구로 이어지도록 강제함으로써 기하학 복원 공격을 완전히 비활성화하는 이점을 갖습니다.

불행히도, 개인 정보 보호 시각적 측위를 위해 구름을 사용하는 것은 두 가지 문제로 인해 쉽지 않습니다. 새로운 유형의 공격이 지도 도심에 대한 장면 세부 정보를 부분적으로 드러낼 수 있습니다. 카메라 포즈가 알 수 없는 스케일까지만 검색될 수 있습니다.

---

### Related works

#### 사적인 장면 세부 정보 복원

희소 포인트 클라우드에서 high-fidelity 장면 세부 정보를 드러내는 데 성공한 첫 번째 방법은 Pittaluga et al.에 의해 제안되었으며 cascaded U-Net을 기반으로 하는 InvSfM이라는 네트워크가 투영된 3차원 포인트의 2차원 위치뿐만 아니라 해당 깊이, RGB 값 및 SIFT 디스크립터를 포함한 일련의 입력으로부터 장면 이미지를 재구성하는 데 사용됩니다.

#### 개인 정보 보호 3차원 장면 표현

장면 이미지 재구성을 위한 InvSfM의 사용을 방해할 목표로, Speciale et al.은 각 포인트가 원래 포인트를 통과하는 무작위로 방향이 지정된 3차원 선으로 표현되어 포인트 위치에 모호성을 도입하여 장면 기하학을 숨기려는 선 클라우드를 제안했습니다.

이것이 처음에 장면 세부 정보를 드러내려는 시도를 차단하는 효과적인 전략으로 인식되고 SLAM으로 확장되었지만, 나중에 Chelani et al.에 의해 균일하게 분포된 선 방향을 가진 선 클라우드가 장면 포인트를 정확하게 복구할 수 있는 밀도 기반 기하학 역전 공격에 취약하며 그로부터 장면 이미지가 후속적으로 드러날 수 있음이 밝혀졌습니다.

#### 3차원 선 클라우드를 사용한 측위

3차원 포인트 클라우드를 포함하는 고전적인 절대 카메라 포즈 추정 문제는 2차원-3차원 포인트 간 제약 조건에서 파생된 효율적인 perspective-n-point (pnP) 솔버로 해결될 수 있습니다.

---

### Methods

<img src="https://velog.velcdn.com/images/devjo/post/241cf63f-dcdf-4a60-9254-4f308b1545e2/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:100;" />

#### 동기 (Motivations)

각 3차원 선에 대한 포인트 후보의 히스토그램을 구성하고 이 히스토그램의 피크를 찾아 3차원 포인트를 복구합니다.

이제 모든 선이 단일 포인트 $\mathbf{c} \in \mathbb{R}^3$에서 만나도록 리프팅되면 두 선이 $\mathbf{c}$서 가장 가깝기 때문에 각 선에 대한 포인트 후보는 항상 교차점에 위치하게 됩니다. 결과적으로, 히스토그램의 피크는 항상 $\mathbf{c}$에 있어 퇴화된 복구로 이어지고 공격을 무효화합니다.

#### 기본 구성 절차 및 한계점

<img src="https://velog.velcdn.com/images/devjo/post/318a904d-b0cb-44fd-b7fa-c588a046ffe8/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

첫째, 교차점을 3차원 포인트 클라우드의 평균 중심으로 설정하여 결과적인 선 방향이 안정적인 측위를 위해 대략적으로 균일하게 분포되도록 보장합니다.

둘째, 모든 3차원 포인트를 지도 중심에 모은 구 상에 투영하여 기본 3차원 구름을 생성합니다.

#### 향상된 구성 전략

구름 포인트로부터의 직접 이미지 합성을 방해하기 위해, 구름에 가짜 포인트를 추가합니다. 이것은 실제 키포인트 사이에 가짜 포인트를 포함시키는 것이 InvSfM을 통해 재구성된 장면 이미지의 품질을 저하시킨다는 관찰에 영감을 받았습니다.

과도한 수의 가짜 포인트가 구름을 밀집하게 만들고 측위 속도를 늦출 수 있으므로, 총 구름 포인트 수를 고정하여 이것을 피합니다. Cloud sparsification 작업에 의해 원하는 참 양성 구름 포인트의 비율이 $\eta$라면, 모든 포인트의 $1-\eta$를 버립니다.

그리고 기존 구름 포인트의 좌표에 가우시안 노이즈를 추가하는 간단한 접근 방식을 사용합니다.

$$
\mathbf{z}_{ij} = \mathbf{\hat{x}}_i + \epsilon
$$

여기서 $\mathbf{\hat{x}}_i \in \mathbb{S}^2$는 $i$번째 구름 포인트이고, $\mathbf{z}_{ij}$는 $\mathbf{\hat{x}}_i$의 근접성에서 생성된 $j$번째 가짜 포인트입니다.

#### RGB 이미지 및 깊이 지도를 사용한 카메라 포즈 추정

쿼리가 정렬된 RGB 이미지와 절대 깊이 지도를 알려진 내부 매개변수와 함께 가지고 있다고 가정하고 구름을 사용한 절대 포즈 추정을 위한 프레임워크를 설명합니다.

$$
\mathbf{p}_i = z_{\text{TOF}, i} \mathbf{K}^{-1} [\mathbf{u}_i^\top, 1]^\top
$$

여기서 $z_{\text{TOF}, i} \in \mathbb{R}$는 ToF 센서에서 얻은 $\mathbf{u}_i$의 깊이이고, $\mathbf{K} \in \mathbb{R}^{3 \times 3}$는 카메라 내부 매개변수입니다.

이상적으로, 3차원 키포인트 $\mathbf{p}_i$는 구름 중심에서 나와 구름 포인트 $\mathbf{\hat{x}}_i$를 통과하는 벡터의 양의 방향을 따라야 합니다.

$$
\mathbf{p}_i = t + \alpha \mathbf{R} \mathbf{\hat{x}}_i
$$

초기 포즈가 얻어진 후 비선형 최적화를 통해 포즈를 개선합니다. 구름은 특별한 유형의 선 클라우드로 간주될 수 있으므로 다른 선 클라우드의 방향을 따라 구름에서 파생된 3차원 선의 투영과 2차원 쿼리 키포인트 사이의 에피폴라 거리의 제곱을 부분적으로 최소화합니다.

$$
\mathcal{L}^e_i = \frac {([\mathbf{u}_i^\top , 1] \mathbf{K}^{-\top } \mathbf{E} \tilde {\mathbf{x}}_i)^2} {(\mathbf{e}_{1}^\top \tilde {\mathbf{x}}_i)^2 + (\mathbf{e}_{2}^\top \tilde {\mathbf{x}}_i)^2}
$$

여기서 $\mathbf{E} := [\mathbf{e}_1, \mathbf{e}_2, \mathbf{e}_3]^\top$는 구름과 쿼리 카메라 사이의 기본 행렬 ($\text{essential matrix}$)을 나타내며, $\mathbf{\tilde{x}}_i = \mathbf{\hat{x}}i/|\mathbf{\hat{x}}{iz}|$는 구름 포인트 $\mathbf{\hat{x}}_i$의 $z$-정규화입니다.

위 식은 병진 스케일을 고려하지 않기 때문에 카메라 포즈를 올바른 스케일로 안내하기 위해 깊이 정규화 항을 추가적으로 사용합니다.

$$
\mathcal{L}_i^d = (\beta_i - 1)^2
$$

$R$과 $t$에서 반복적으로 최소화되는 전체 비용함수는 다음과 같습니다.

$$
\mathcal{L} = \sum _{i\in \Omega } \left ( \mathcal{L}_i^e + \lambda \mathcal{L}_i^d \right )
$$

---

### Conclusion

본 연구에서 선 클라우드에 대한 알려진 기하학 복원 공격을 무력화할 수 있는 sphere cloud라고 불리는 새로운 개인 정보 보호 장면 표현을 제시했습니다.

이 표현을 실현하는 데 있어서의 주요 도전 과제, 즉 지도 도심에 대한 구름 포인트에서 이미지를 직접 드러내는 새로운 유형의 공격의 가능성과 해결되지 않은 병진 스케일의 문제를 주목했습니다.

직접적인 이미지 재구성을 저지하기 위해 재활용된 실제 디스크립터를 가진 가짜 포인트를 도입하고 병진 스케일을 안내하기 위해 효율적인 RGB-D 개인 정보 보호 측위 프레임워크를 제시함으로써 이러한 문제를 해결했습니다.

다만 노이즈가 많은 깊이 측정으로 인해 더 낮은 병진 정확도를 나타냅니다.

---

### 참고 자료

[원본 경로 #1](https://bmva-archive.org.uk/bmvc/2024/papers/Paper_267/paper.pdf)
