---
title: 'TWINVLA: DATA-EFFICIENT BIMANUAL MANIPULATION WITH TWIN SINGLE-ARM VISION-LANGUAGEACTION MODELS'
date: '2025-12-01'
tags: ['embodied ai', 'paper review']
---

### Abstract

대규모 로봇 데이터셋에서 훈련된 비전-언어-행동 모델 (VLA, Vision-Language-Action Models)은 양팔 작업을 포함하여 조작 작업에서 강력한 성능을 보여주었습니다. 그러나 대부분의 공개 데이터셋이 단일 팔 시연에 초점을 맞추고 있기 때문에, 양팔 작업을 위해 VLA를 적응시키는 것은 일반적으로 상당한 추가 양팔 데이터와 파인 튜닝을 필요로 합니다.

이러한 도전 과제를 해결하기 위해, 사전 훈련된 단일 팔 VLA의 두 복사본을 조정된 양팔 VLA로 구성하는 모듈식 프레임워크인 TwinVLA를 소개합니다.

단일 팔 및 양팔 데이터의 혼합으로 훈련된 모놀리식 교차 구현체 모델과 달리, TwinVLA는 사전 훈련된 단일 팔 정책을 구성함으로써 데이터 효율성과 성능 모두를 향상시킵니다.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/16acf27d-247d-46e9-afd4-33394b3155ff/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

공개적으로 이용 가능한 대규모 로봇 데이터셋 덕분에 비전-언어-행동 모델 (VLA)은 단일 팔 로봇 조작에서 인상적인 성능을 보여주었으며, 다양한 작업, 객체, 및 환경에 걸쳐 일반화되었습니다.

그러나 양팔 조작으로 이러한 성공을 확장하는 것은 여전히 어렵습니다. 공개 양팔 데이터셋이 희소하고 기존 접근 방식이 수천 시간의 데이터 수집과 큐레이션을 요구하는 대규모 독점 데이터셋에 의존하는 경우가 많아 재현성과 발전을 제한하기 때문입니다.

#### 단일 팔 데이터의 활용

최근 교차 구현체 학습 연구는 구현체별 행동 디코더를 사용하거나 공유된 제로 패딩된 행동 공간을 사용하여 다중 로봇 데이터셋 상에서 모놀리식 모델을 훈련합니다 (Open X-Embodiment Collaboration et al., 2024). 이것이 유망하지만 관찰 및 행동 공간의 차이는 이질성을 도입하여 단일 모델이 서로 다른 행동 공간을 처리하도록 강제하고 모놀리식 훈련은 양팔 작업에 내재된 모듈식 구조를 충분히 활용하지 못합니다.

#### 모듈식 접근 방식의 영감

양팔 조작에 대한 모듈식 관점은 신경과학에 의해 뒷받침됩니다. 인간 양팔 조작은 단일 모놀리식 컨트롤러가 아닌 팔별 모터 원시 요소의 조정입니다.

보조 운동 영역 및 corpus callosum과 같은 전용 신경 회로는 두 팔을 조정하고 동기화합니다.

#### TwinVLA 제안

구체적으로 SingleVLA라고 부르는 경량의 컴팩트한 단일 팔 VLA를 설계합니다. 두 개의 VLA를 양팔 정책으로 통합하기 위해 joint attention를 활용합니다. 이릁 통해 사전 훈련된 능력을 보존하면서 정보를 교환하고 행동을 조정할 수 있도록 합니다.

MoE ($Mixture-of-Experts)를 활용하기 때문에 상당한 오버헤드 없이 실현 가능합니다.

---

### Methods

<img src="https://velog.velcdn.com/images/devjo/post/c7469978-61f6-4517-8ad5-52570eddf403/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

#### 단일 팔 정책 복제

SingleVLA에서 TwinVLA를 구성하기 위해 사전 훈련된 SingleVLA를 복사하여 왼쪽 및 오른쪽 팔을 위한 쌍둥이 정책을 초기화합니다. 전체 모델을 복제하는 대신 시각 인코더와 DiT (Peebles & Xie, 2022) 행동 헤드를 공유하는 동시에 VLM을 완전히 복제합니다.

각 팔은 자신의 경량 고유 수용성 인코더를 가집니다. 이 디자인은 계산 비용을 크게 증가시키지 않고 컴팩트한 1.3B 매개변수 모델을 산출합니다.

시각적 입력은 공유 인코더에 의해 처리되고 공유 DiT에 의해 공동으로 디코딩되는 읽기 토큰을 생성합니다.

#### 교차 팔 융합을 위한 공동 주의

MoT (Mixture of Transformers)에서 영감을 받은 공동 주의 메커니즘을 사용하여 팔별 입력을 통합합니다. self-attention레이어만 공유하는 동시에 투영 네트워크와 같은 다른 구성 요소는 각 팔에 대해 독립적으로 작동함으로써 달성됩니다.

표준 LLM은 인과적 예측을 위해 하삼각 주의 마스크 (lower-triangular attention mask)를 사용합니다. 구체적으로 공유 모달리티를 완전히 접근 가능한 것으로 처리하는 동시에 각 팔의 영역 내에 하삼각 마스크를 임베딩합니다. 각 팔은 또한 다른 팔의 토큰의 절반에 주의를 기울여, 자기 회귀 제약 조건을 위반하지 않고 대칭적인 교차 팔 상호 작용을 가능하게 합니다.

---

### Conclusion

본 논문에서, 사전 훈련된 단일 팔 VLA의 표현을 양팔 작업에 맞게 조정하므로, 현재 한계점은 파인 튜닝 후 모델이 단일 팔 조작 기술을 잊어버린다는 것입니다. 이러한 망각을 방지하는 메커니즘에 대한 향후 연구는 다양한 데이터를 통합하여 데이터 희소성을 해결할 수 있으며, 동시에 모델 설명 가능성을 향상시키고 보이지 않는 작업에 대한 더 나은 일반화 능력을 개선할 수 있습니다.

또한, 행동 공간의 선택은 VLA 모델, 특히 지식 이전에 있어 중요합니다. EEF(End-Effector) 자세 제어를 채택한 것은 단일 팔 이전 전략에 필수적인 구현체 불가지론적 표현을 제공하기 때문입니다.

결과적으로 TwinVLA는 풍부한 단일 팔 데이터셋을 활용하여 희소한 양팔 데이터 하에서 양팔 조작을 해결하는 데 대한 새로운 관점을 제공합니다.

모듈성을 활용하여 데이터 가용성 격차를 해소하는 이 원칙이 모바일 조작과 같은 다른 복잡한 로봇 영역에 대한 흥미로운 가능성을 열어주어, 대규모 로봇 학습의 영향을 확대할 수 있다고 믿습니다.

---

### 참고 자료

[원본 경로 #1](https://arxiv.org/pdf/2511.05275)
