---
title: 'Open vocabulary Mobile Manipulation in Unseen Dynamic Environments with 3D Semantic Maps'
date: '2025-10-18'
tags: ['embodied ai', 'paper review']
---

### Abstract

개방형 어휘 이동 조작 (OVMM, Open-Vocabulary Mobile Manipulation)은 자율 로봇에게 미지의 동적 환경이 야기하는 도전에 직면했을 때 결정적인 능력입니다. 이 작업은 로봇이 주변 환경을 탐색하고 의미론적 이해를 구축하며, 조작 목표를 달성하기 위한 실행 가능한 계획을 생성하고, 환경 변화에 적응하며, 인간의 자연어 명령을 이해하도록 요구합니다.

이러한 도전에 대처하기 위해, 사전 훈련된 시각-언어 모델 (VLM)의 제로샷 탐지 및 접지된 인식 능력을 조밀한 3D 엔티티 재구성과 결합하여 3D 의미 지도를 구축하는 새로운 프레임워크를 제안합니다.

추가적으로, 인간 명령과 공간 의미론적 맥락을 통합하여 공간 영역 추상화 및 온라인 계획을 위해 대규모 언어 모델 (LLM)을 활용합니다.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/5850c23c-52c3-43be-b2d4-8680e5d996ba/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

이동 조작 (Mobile manipulation)은 자율 로봇의 필수적이고 근본적인 능력입니다. 최근 사전 훈련된 LLM과 VLM의 급증과 로봇 공학과의 통합은 네비게이션 및 이동 조작 작업에서 자율 로봇을 위한 개방형 어휘(open vocabulary) 및 제로샷(zero shot) 능력 분야에서 상당한 관심을 받고 있습니다.

게다가, 이전에 보지 못한 환경에 대한 사전 지식 부족과 설정을 변화시키는 동적 요인은 문제를 더욱 복잡하게 만듭니다. 그러나 이 두 가지 문제를 해결하는 것은 로봇이 제너럴리스트가 되고 더 넓은 범위의 실제 작업에 실질적으로 적용 가능하도록 개발하는 데 결정적입니다.

#### Two stage Approach

1단계로 3D 의미 지도(Semantic Mapping) 구축에서 로봇은 휴리스틱 알고리즘으로 환경을 탐색하며, 로봇의 순차적 관찰은 SLAM (Simultaneously Location and Mapping) 파이프라인으로 들어가 내비게이션을 위한 조밀한 3D 구조를 재구성합니다. LLM과 VLM의 개방형 어휘 탐지 및 제로샷 추상 추론 능력을 활용하는 의미 추출 및 추상화 파이프라인을 통해 개방형 어휘 내비게이션 및 이동 조작을 위한 3DSMap에 포착된 환경의 의미론적 이해를 구축합니다.

2단계로 의미 인식 개방형 어휘 이동 조작에서 로봇은 자연어로 주어진 인간의 명령과 힌트를 구문 분석하고 LLM을 사용하여 해당하는 의미론적으로 최적인 영역 검색 계획을 제시합니다. 이후 VLM의 전통적인 검색 기반 및 확률적 경로 및 동작 계획기가 객체를 탐지하여 표적 객체를 집어들고 사용자에게 반환합니다.

---

### Methods

#### 작업 목표 및 맥락

작업 목표는 로봇이 개방형 어휘 설정에서 인간 사용자에게 객체를 찾아 가져다주는 것입니다.

#### Formulation

공식적으로 $(\mathbf{g_o}, \mathbf{g_R})$ 튜플로 설명될 수 있습니다. 로봇은 사용자로부터 목표에 대한 자연어 명령 $L$을 받습니다. 사용자가 제공하는 힌트 $\mathbf{\hat{g}_R}$는 선택 사항이며, 사용자의 잘못된 기억이나 환경의 동적 변화로 인해 때때로 오해의 소지가 있을 수 있음을 유의하십시오. 성공적인 실행에서는 로봇이 표적 영역 $\mathbf{g_R}$에 도달하고, 표적 객체 $\mathbf{g_o}$를 집어 들어 사용자에게 반환해야 합니다.

#### 3D Semantic Mapping in Unseen Environments

<img src="https://velog.velcdn.com/images/devjo/post/21b29a56-3e04-4447-916b-6d4064e9c5eb/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

사전 지식이 전혀 없는 미지의 환경에서, 로봇이 환경 구조를 인식하고 나아가 환경에 대한 의미론적 이해를 구축하는 것이 필수적입니다. 휴리스틱 프론티어 탐색 알고리즘은 로봇이 환경을 탐색하는 데 사용됩니다. 로봇의 RGB-D 카메라와 IMU로부터의 순차적인 시각-관성 감지 입력이 기록되며, 각각 타임스탬프 $t$와 연관된 RGB 이미지 프레임 $\{\text{I}_{\text{RGB}}^{t}\}$ 및 깊이 프레임 ${\text{I}_{\text{D}}^{t}}$와 $\text{IMU}$ 측정값 ${I^{t}}$로 구성됩니다.

훈련 없는 방식으로 환경의 의미 인식을 구축하기 위해, 2D 개방형 어휘 탐지 및 픽셀 단위 분할을 위해 Grounded SAM 파이프라인을 채택합니다.

키 프레임 $k$의 각 RGB 이미지 프레임에 대해, Grounding DINO와 같은 개방형 어휘 탐지 모델로 객체 인스턴스 $\mathbf{\{b}^{(k,i)}\}_{i=1}^{N_k}$를 탐지하고 마스크로 분할합니다.

인스턴스 의미 계층에 추출되고 등록된 인스턴스 $\mathbf{\{q}^{(k,i)}\}$는 기하학적 중심 $\mathbf{\bar{p}}^{(k,i)}$에서 높이 차원을 단순히 제거하여 2D 평면에 투영되어 2D 조감도 의미 지도를 형성합니다.

#### 의미 인식 개방형 어휘 이동 조작

로봇은 표적 객체 $\mathbf{g_o}$를 가져오도록 요청하는 이동 조작 작업의 목표에 대한 자연어 명령 $L$을 사용자로부터 받습니다. 표적 객체 $\mathbf{g_o}$는 영역 의미 추상화에서 얻은 장면에 존재하는 영역 $\text{S}_R$의 목록과 함께 템플릿 $\text{T}_{\text{Prioritization}}$을 가진 사전 훈련된 LLM에 입력되어 표적 객체 $\mathbf{g_o}$와 $\text{S}_R$의 각 영역 간의 의미론적 관련성에 따라 영역의 우선순위를 지정합니다. $L$에서 사용자가 제안한 영역 $\mathbf{\hat{g}_R}$에 가장 높은 우선순위를 할당하는 선택적인 재우선순위 지정 단계가 뒤따릅니다.

접지된 로봇의 이동 조작을 고려하므로, 계산 복잡성을 줄이기 위해 3DSMaps의 구조적 계층은 내비게이션을 위해 2D 비용 지도로 평탄화됩니다.

영역 $R$의 검색 가능한 위치 $p$에 도달하면, 로봇은 $\text{T}_{\text{cam}}$ 카메라 포즈를 위한 최종 이펙터 계획을 수행하여 $p$의 작업 영역을 바라봅니다.

---

### Conclusion

본 연구에서 개방형 어휘 이동 조작 (OVMM) 문제를 다루는 새로운 프레임워크를 제안했습니다.

이 프레임워크는 사전 훈련된 시각-언어 모델 (VLM)의 제로샷 탐지 및 접지된 인식 능력을 조밀한 3D 엔티티 재구성과 결합하여 3D 의미 지도를 구축합니다.

향후 연구에서는 자율 탐색 기술을 통합하여 미지의 환경으로 시스템의 능력을 확장하는 데 집중할 것입니다.

---

### 참고 자료

[원본 경로 #1](https://arxiv.org/pdf/2406.18115)
