---
title: 'World Model Implanting for Test-time Adaptation of Embodied Agents'
date: '2025-09-28'
tags: ['embodied ai', 'paper review']
---

### Abstract

체화된 AI (Embodied AI)에서 지속적인 도전 과제는 광범위한 데이터 수집이나 재훈련 없이 에이전트가 새로운 도메인에 강력하게 적응할 수 있도록 하는 것입니다.

이를 해결하기 위해, 대규모 언어 모델 (LLM)의 추론 능력과 독립적으로 학습된 도메인별 월드 모델을 테스트 시점 합성을 통해 결합하는 월드 모델 주입 프레임워크 (WorMI)를 제시합니다. 월드 모델의 원활한 주입 및 제거를 허용함으로써, 체화된 에이전트의 정책은 교차 도메인 적응성을 달성하고 유지합니다.

WorMI 프레임워크에서는 효율적인 궤적 기반 추상 표현 매칭을 활용하는 프로토타입 기반 월드 모델 검색 접근 방식을 사용하여 관련 모델을 테스트 시점 합성에 통합합니다. 또한, 검색된 월드 모델로부터의 지식을 통합할 뿐만 아니라, 그들의 중간 표현을 에이전트 정책 내의 추론 모델의 표현과 정렬시키는 월드 단위 복합 어텐션 (world-wise compound attention) 방법을 개발합니다. 이 프레임워크 설계는 다중 월드 모델로부터 도메인별 지식을 효과적으로 융합하여, 미지의 도메인에 대한 강력한 적응을 보장합니다.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/76d75f02-7261-4519-b845-c9660a373947/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:200;" />

최근 몇 년간, 대규모 언어 모델 (LLM)에 기반한 정책들은 순차적 의사 결정을 내리고 탐색 및 조작과 같은 작업을 통해 물리적 환경과 상호 작용할 수 있는 지능형 에이전트를 만드는 분야인 체화된 AI (embodied AI)에서 놀라운 성공을 보여주었습니다 (Huang et al., 2022a;b; Yao et al., 2022; Wang et al., 2023).

그러나 광범위한 데이터 수집이나 재훈련 없이 에이전트가 미지의 도메인에 효과적으로 적응할 수 있도록 하는 데에는 중요한 도전 과제가 남아 있습니다. 이러한 적응성은 환경 변화와 다양한 목표로 인해 엄격한, 도메인별 정책이 부적절하거나 비효율적인 경우가 많은 실제 응용 분야에 매우 중요합니다.

인-컨텍스트 적응 접근 방식은 다중 도메인에서 관련 데이터를 검색하여 주어진 상황에 가장 적절한 정보를 식별합니다. 어느 정도의 유연성을 제공하지만, 방대한 양의 정보를 검색, 검색 및 처리하는 오버헤드로 인해 종종 비효율성을 겪습니다. 반면에, 모델 통합 접근 방식은 도메인별 측면, 비용을 일반 지식과 명시적으로 분리하여 서로 다른 속성을 가진 두 개 이상의 모델을 결합합니다. 이는 사전 지식의 효율적인 사용을 목표로 하지만, 본질적으로 학습된 도메인을 넘어서 지식을 확장하는 유연성이 부족합니다.

WorMI 프레임워크는 LLM 기반 체화된 에이전트에 맞게 조정된 적응적이고 구성 가능한 정책 구조에 두 가지 핵심 방법을 통합합니다. 프로토타입 기반 월드 모델 검색 방법에서는 관련된 월드 모델 세트만을 선택적으로 활성화하고 관련성을 결정하기 위해, 궤적 기반 프로토타입에서 파생된 객체별 상태 임베딩과 군집 결과를 사용하여 현재 타겟 도메인과의 각 모델의 유사성을 측정합니다. 월드 단위 복합 어텐션 방법에서는 검색된 모델 세트에서 관련 지식을 적응적으로 결합함으로써 월드 모델을 추론 모델과 효과적으로 통합합니다.

---

### Related works

#### LLM-based Embodied Agent

LLM 기반 체화된 에이전트의 작업은 종종 체화된 명령어 추종 (embodied instruction following)으로 불리며, 객체 조작 및 탐색과 같은 활동을 통해 물리적 환경과 상호 작용하고 환경 역학 및 관찰에 대한 고수준 이해를 필요로 합니다. 최근 연구는 이러한 에이전트의 추론 및 계획 능력을 향상시키기 위한 다양한 기술을 탐구해 왔습니다. 여기에는 코드 기반 정책 구현 (Singh et al., 2023; Liang et al., 2023), 보상 함수 생성 (Yu et al., 2023; Adeniji et al., 2023; Kim et al.), 그리고 환경에서 기술의 행동 유도성 ($\text{affordances}$) 또는 가치를 활용하기 위해 $\text{LLM}$을 추가적인 도메인별 모델과 통합 (Brohan et al., 2023; Hazra et al., 2024)하는 것이 포함됩니다. 또한, 이전 시연을 추론 과정의 일부로 통합하는 인-컨텍스트 학습 접근 방식 (Song et al., 2023)도 도입되었습니다.

이러한 접근 방식들은 체화된 명령어 추종을 위한 LLM의 유연성과 강건성을 강조하지만, 종종 환경 데이터 또는 추가 모델의 외부적이고 단절된 통합에 의존하여 응집력을 제한합니다. 더욱이, 그들은 미지의 도메인에 대한 적응을 용이하게 하기 위해 다중 도메인별 모델을 효과적으로 통합하는 문제를 거의 다루지 않습니다. 이와 대조적으로, 우리의 연구는 다중 월드 모델을 LLM 추론에 주입하는 확장 가능한 접근 방식을 도입하여 매우 유연하고 쉽게 교체 가능한 정책을 가능하게 합니다. 이러한 설계는 주의 기반 (attention-driven), 신중하게 선택된 다중 모델로부터의 일관된 지식 통합을 통해 다양한 도메인에 걸친 강력한 일반화와 신속한 적응을 용이하게 합니다.

#### Cross-domain Policy Adaptation

다양한 환경 특징 및 작업을 처리하는 문제를 해결하기 위해, 연구자들은 다양한 도메인 일반화 방법 (Zhou et al., 2022)을 연구해 왔습니다. 대표적인 접근 방식으로는 다중 작업을 학습하는 방법을 학습하는 메타 학습 (Finn et al., 2017; Nichol, 2018; Andrychowicz et al., 2016; Ha et al., 2016), 도메인 속성을 분해하여 다중 수준에 걸쳐 지식을 구조화하는 계층적 학습 (hierarchical learning), 그리고 더 강건한 성능을 위해 도메인별 신경망을 훈련하는 앙상블 학습 ($\text{ensemble learning}$)이 있습니다. 그러나 이러한 방법들은 종종 도메인별 모델에 포함된 특화된 지식을 완전히 활용하는 데 미흡합니다. 본 논문에서 제안한 프레임워크는 이러한 기존 접근 방식의 이점을 확장하여 다양한 도메인별 월드 모델을 단일 정책에 주입합니다. 이는 광범위한 도메인에 걸쳐 효과적인 적응을 가능하게 합니다.

---

### Methods

<img src="https://velog.velcdn.com/images/devjo/post/dd47101c-61cc-423f-a5c1-4ed4a7bb6938/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:200;" />

#### Overall Framework

LLM 기반 체화된 에이전트의 핵심 과제는 도메인별 지식을 일반 추론 모델에 합성하여 에이전트가 광범위한 미지의 도메인을 처리할 수 있도록 하는 것입니다. 에이전트가 테스트 시점에 관련 월드 모델을 동적으로 검색하고 합성하여, 이를 LLM 기반 정책에 융합할 수 있도록 하는 WorMI 프레임워크를 제시합니다. 이 접근 방식은 대규모 모델의 재훈련이나 미세 조정 없이 끊임없이 변화하는 환경에서 다양한 도메인에 걸쳐 강력한 제로샷 및 퓨샷 적응을 보장하는 것을 목표로 합니다.

WorMI에서는 도메인 $\mathcal{D}_1, \dots, \mathcal{D}_N$으로부터의 해당 데이터 세트 $\mathcal{D}_1, \dots, \mathcal{D}_N$와 함께 사전 훈련된 월드 모델 $M_1, \dots, M_N$의 가용성을 가정합니다. LLM을 기반으로 구축된 추론 모델 $\pi_R$은 일반적인 추론 및 의사 결정 능력을 제공합니다. 이러한 개별 모델들을 고려하여, 사전 훈련된 월드 모델의 관련 부분 집합 $\{M_1, \dots, M_K\}$만을 고정된 추론 모델 $\pi_R$과 선택적으로 통합하는 훈련 가능한 합성 모듈 $C_\theta$를 도입합니다. 계층적 접근 방식은 먼저 다중 월드 모델을 통합된 표현으로 융합한 다음, $\pi_R$과 정렬하여 주입된 정책 $\pi_\theta = C_\theta(\{M_1, \dots, M_K\}, \pi_R)$을 형성합니다.

#### Prototype Based

각 도메인별 월드 모델 $M_j$는 해당 데이터 세트 $\mathcal{D}_j = \{(I, s_t, a_t, s_{t+1})\}$에서 훈련됩니다. 여기서 $I$는 체화된 작업 명령어를 나타내고, $s_t$는 시점 $t$에서의 에이전트의 상태이며, $a_t$는 실행된 행동입니다. 훈련은 세 가지 보조 작업으로 구성됩니다.

dynamics task가 주어졌을 때 다음 상태를 예측하고 action affordance task에서는 현 상태로부터 실행 가능한 행동을 식별합니다. 그리고 behavior cloning task에서는 정책을 학습하여 각 월드 모델에게 전이, 행동 유도, 의사 결정에 대한 지식을 부여합니다.

주어진 상태 $s_t$에 대해 관련성을 기반으로 월드 모델 세트 $M_{\text{ret}}$를 검색합니다. 이 선택은 각 데이터 세트 $\mathcal{D}_j$에 대한 환경의 객체별 상태를 인코딩하는 임베딩 세트 $E_j$와 $s_t$로부터 파생된 임베딩 세트 $E$ 사이의 임베딩 세트 거리를 측정하여 이루어집니다. 따라서 검색된 세트 $M_{\text{ret}}$는 다음과 같이 공식화될 수 있습니다.

$$
M_{\text{ret}} = \left\{ M_j \mid j \in \text{Top}K \left( \left\{ -\delta(E_j, E) \right\}_{j=1}^N, K \right) \right\}
$$

여기서 $K$는 선택된 월드 모델의 수이며, $\delta(\cdot, \cdot)$는 바서슈타인 거리 ($\text{Wasserstein distance}$)입니다. 그러나 이러한 세트 거리를 직접 계산하는 것은 높은 계산 비용을 초래하며, 데이터 세트에서 자주 발생하는 객체를 과대 대표하는 경향이 있습니다. 따라서 테스트 시점에 계산 오버헤드를 줄이면서 표현 다양성을 유지하기 위해 프로토타입 기반 유사성을 채택합니다.

이러한 신뢰할 수 있는 프로토타입을 얻기 위해, 입력 상태를 객체별 상태로 변환하는 객체 감지 모델 $\Phi_D$와 언어 또는 시각 임베딩 모델을 사용하여 구현할 수 있는 임베딩 모델 $\Phi_E$를 사용하여 객체별 방식으로 임베딩 세트 $E_j$를 구성합니다.

$$
E_j = \left\{ \Phi_E(o) \mid o \in \{o_1, \dots, o_n\} = \Phi_D(s), s \in \mathcal{D}_j \right\}
$$

여기서 $o$는 상태 $s$에 대한 객체별 상태를 나타냅니다. $k$-중심 방법 ($\text{k-center method}$)을 사용하여 $E_j$를 군집화하여 프로토타입을 도출하고, 임의의 지점에서 가장 가까운 중심까지의 최대 거리를 최소화하는 상위 $k$개 임베딩을 식별합니다. 이 접근 방식은 중요한 객체 임베딩을 유지하는 동시에 전체 데이터 세트에 대한 광범위한 거리 계산의 필요성을 줄입니다.

#### Worldwise Compound Attention

<img src="https://velog.velcdn.com/images/devjo/post/5e913c0b-6fa1-478e-accc-c02683d418d1/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:200;" />

정책에서 월드 모델 세트를 추론 모델과 통합하기 위해, 계층적 교차 어텐션을 활용하여 도메인별 지식을 효과적으로 융합하고 테스트 시점에 LLM 추론과 정렬하는 월드 단위 복합 어텐션 방법을 개발합니다.

Compound Attention $C_\theta$는 월드 모델의 $i$번째 계층 출력 $l_{M_1}, l_{M_2}, \dots, l_{M_K}$와 추론 모델의 $j$번째 계층 출력 $l_{\pi_R}$을 추론 모델의 $(j+1)$번째 계층 입력으로 매핑합니다.

$$
l_{\pi_R} + C_\theta(\{l_{M_1}, l_{M_2}, \dots, l_{M_K}\}, l_{\pi_R}) 
$$

선형 투영 계층 $L_\theta$, 월드 수준 교차 어텐션 계층 $\text{Attn}_\theta^W$, 및 추론 수준 교차 어텐션 계층 $\text{Attn}_\theta^R$로 구성됩니다. 선형 투영 계층은 월드 모델의 중간 계층 표현의 차원을 추론 모델의 차원과 일치시킵니다. 월드 수준 교차 어텐션 계층은 가중 조합을 통해 이러한 중간 표현을 통합합니다. 그런 다음 추론 수준 교차 어텐션 계층은 통합된 표현을 추론 모델의 쿼리를 기반으로 정렬합니다.

#### Meta Learning

미지의 도메인에 대한 신속한 적응을 가능하게 하기 위해, WorMI는 복합 어텐션 $C_\theta$에 대해 메타 학습 접근 방식 (Nichol, 2018)을 통합합니다. 이 접근 방식은 $C_\theta$를 기존 모델을 추론 모델과 연결하는 것을 넘어, 다중 월드 모델로부터 도메인별 지식을 동적으로 집계하고 정렬하는 매개변수 효율적인 합성 장치 (composer)로 취급합니다.

각 내부 루프 업데이트 (inner-loop update)에서 매개변수 $\theta_j$는 메타 매개변수 $\theta$로 초기화됩니다.

$$
\mathcal{L}(\theta_j, \mathcal{B}) = \sum_{(s, a) \in \mathcal{B}} - \log \pi_{\theta_j}(a | s)
$$

여기서 $\mathcal{B}$는 $\mathcal{D}_j$에서 샘플링된 배치입니다. 외부 루프 업데이트 (outer-loop update)에서는 $\theta \leftarrow \theta + \beta \cdot \frac{1}{m} \sum_{j=1}^m (\theta_j - \theta)$와 같이 적응된 매개변수를 메타 매개변수로 다시 결합합니다. 여기서 $\beta$는 외부 루프 업데이트의 학습률입니다. 이 프로세스는 $C_\theta$가 단 몇 단계의 기울기만으로 미지의 도메인에 특화될 수 있는 일반적인 통합 및 정렬 전략을 학습하도록 장려합니다. 결과적으로, 복합 어텐션은 추론 과정에서 도메인별 지식을 융합하는 합성 장치 역할을 하며, 새로운 도메인과 새롭게 도입된 월드 모델 모두에 대한 신속한 적응을 가능하게 합니다.

---

### Conclusion

본 논문에서 체화된 정책이 테스트 시점에 고정된 추론 모델과 다중 월드 모델을 동적으로 합성하여 교차 도메인 적응성을 향상시키는 WorMI 프레임워크를 제시했습니다. 프로토타입 기반 월드 모델 검색과 월드 단위 복합 어텐션을 결합함으로써, WorMI는 월드 간 지식 통합과 월드-추론 정렬을 포함하는 이중 단계 지식 융합을 달성합니다. VirtualHome 및 ALFWorld에서의 평가 결과는 WorMI가 제로샷 및 퓨샷 시나리오 모두에서 미지의 도메인에 대한 강력한 적응을 달성하며, 여러 LLM 기반 기준선을 능가함을 확인시켜 줍니다.

---

### 참고 자료

[원본 경로 #1](https://arxiv.org/pdf/2509.03956?)
