---
title: 'Octo: An Open-Source Generalist Robot Policy'
date: '2025-06-02'
tags: ['robotics', 'paper review']
---

### Abstract

다양한 로봇 데이터셋으로 사전 훈련된 대규모 정책(Large policies)은 로봇 학습을 혁신할 잠재력을 가지고 있습니다. 이러한 범용 정책(generalist robot policies)은 새로운 정책을 처음부터 훈련할 필요 없이, 적은 양의 해당 영역 데이터(in-domain data)만으로도 미세 조정(finetuned)될 수 있으며 광범위하게 일반화될 수 있습니다.

본 연구에서 로봇 조작을 위한 오픈 소스이며 광범위하게 적용 가능한 범용 정책을 개발하기 위한 기반을 다지는 것을 목표로 합니다. Open X-Embodiment 데이터셋에서 가져온 80만 개의 로봇 궤적으로 훈련된 Octo라는 트랜스포머 기반의 확산 정책(transformer-based diffusion policy)을 소개합니다. Octo는 언어 명령이나 목표 이미지를 통해 지시를 받을 수 있으며, 표준 소비자용 GPU로 몇 시간 내에 새로운 감각 입력과 행동 공간을 가진 로봇 설정에 효과적으로 미세 조정될 수 있습니다.

---

### Introduction

<img src="https://velog.velcdn.com/images/devjo/post/63e191fa-5a83-429e-a45d-a65e582793d7/image.png" alt="Example Image" style="display: block; margin: 0 auto; height:150;" />

로봇 학습을 위한 일반적인 접근 방식은 당면한 특정 로봇과 작업을 위해 수집된 데이터 세트로 정책을 훈련하는 것입니다. 이는 단순하고 신뢰할 수 있는 방식이지만 맨 처음부터 학습하는 것은 각 작업마다 상당한 데이터 수집 노력이 필요하며, 정책은 데이터 수집 설정 외에는 좁게만 일반화될 수 있습니다. 원론적으로, 다른 로봇 및 작업에서 수집된 경험은 모델을 다양한 로봇 제어 문제에 노출시켜, 후속 작업에서의 일반화 및 성능을 향상시킬 수 있는 가능한 해결책을 제공합니다.

최근, 여러 연구에서 로봇 관찰을 행동에 직접 매핑하고 새로운 도메인 및 로봇에 대한 제로샷 또는 소수샷 일반화를 제공하는 모델이 제안되었습니다. 작업, 환경, 로봇 시스템 전반에 걸쳐 저수준의 시각-운동 제어(visuomotor control)를 예측하는 능력에 중점을 둡니다.

Octo는 높은 유연성을 제공합니다. 기본적으로 여러 RGB 카메라 입력을 지원하며, 다양한 로봇 팔을 제어하고, 언어 명령 또는 목표 이미지를 통해 지시를 받을 수 있습니다. 더욱 중요한 점은, Octo의 트랜스포머 백본에 있는 모듈식 어텐션 구조 덕분에 새로운 감각 입력, 동작 공간 및 형태를 가진 로봇 설정에 대해 적은 양의 목표 도메인 데이터와 접근 가능한 계산 예산만으로도 효과적인 미세 조정이 가능합니다.

---

### Methods

#### Architecture

Octo 모델의 설계는 유연성과 규모를 강조합니다. 이 모델은 일반적으로 사용되는 다양한 로봇, 센서 구성, 행동을 지원하도록 설계되었으며, 동시에 대량의 데이터로 훈련할 수 있는 일반적이고 확장 가능한 레시피를 제공합니다. Octo는 핵심적으로 트랜스포머 기반 확산 정책 $\pi$입니다. 이는 세 가지 주요 부분으로 구성됩니다. 입력 토크나이저에서 언어 지침 $l$, 목표 $g$, 관찰 시퀀스 $o_{1}, \dots, o_{H}$를 토큰 $T_l, T_g, T_o$로 변환합니다. 트랜스포머 백본에서 토큰을 처리하고 임베딩 $e_l, e_g, e_o = T(T_l, T_g, T_o)$를 생성합니다. 읽기 헤드인 $R(e)$에서 원하는 출력, 즉 행동 $a$를 생성합니다. 언어 지침 $l$ 및 목표 이미지 $g$와 같은 작업 정의와 손목 및 3인칭 카메라 스트림과 같은 관찰 $o$를 양식별 토크나이저를 사용하여 공통의 토큰화된 형식으로 변환합니다. 언어는 토큰화되어 사전 훈련된 트랜스포머를 통과하여 언어 임베딩 토큰 시퀀스를 생성합니다. 이미지와 목표는 얕은 컨볼루션 스택을 통과한 후, 평탄화된 패치 시퀀스로 분할됩니다. 학습 가능한 위치 임베딩 $p$를 작업 및 관찰 토큰에 추가하고, 이를 순차적으로 배열하여 트랜스포머의 입력 시퀀스를 조립합니다.

$$
\{T_T, T_{o,1}, T_{o,2}, \dots\}
$$

Octo 트랜스포머의 어텐션 패턴은 블록 단위로 마스킹됩니다. 관찰 토큰은 동일하거나 이전 시간 단계 $T_{o,0:t}$의 토큰 및 작업 토큰 $T_T$ (녹색)에만 인과적으로 어텐션할 수 있습니다. 존재하지 않는 관찰에 해당하는 토큰은 완전히 마스킹됩니다. 이러한 입력 토큰 블록 외에도 학습된 읽기 토큰 $T_{R,t}$ (보라색)를 삽입합니다. $T_{R,t}$의 읽기 토큰은 시퀀스에서 그 앞에 있는 관찰 및 작업 토큰에 어텐션하지만, 어떤 관찰 또는 작업 토큰으로부터도 어텐션을 받지 않습니다. 따라서, 이는 내부 임베딩에 영향을 미치지 않고 수동적으로 내부 임베딩을 읽고 처리할 수만 있습니다.

#### Design Decisions

이전의 트랜스포머 기반 정책 설계는 일반적으로 큰 ResNet 스타일 인코더로 입력 이미지를 인코딩하고, 이후 비교적 작은 트랜스포머로 여러 입력을 융합합니다. 하지만 본 논문에서는 매우 얕은 CNN 패치 인코더를 사용하고 대부분의 매개변수와 FLOPS를 모든 입력을 공동으로 처리하기 위한 트랜스포머 백본에 집중시키는 트랜스포머 우선 아키텍처를 선택합니다. 이는 모델이 확장 가능한 트랜스포머 백본을 사용하여 모든 작업 및 관찰에 대한 대부분의 처리를 공동으로 수행할 수 있기 때문일 수 있습니다.

대부분의 처리가 트랜스포머 백본에서 일어나도록 가능한 한 간단한 입력 인코딩을 갖기 위해 노력하지만, 훈련 속도와의 본질적인 절충이 있습니다. 트랜스포머 계산 요구 사항은 컨텍스트 길이에 대해 제곱으로 증가하므로 각 입력을 개별적으로 인코딩하면 많은 수의 토큰이 발생하고 훈련 및 추론 속도가 느려집니다. 목표 이미지를 통합하기 위해, 관찰 이미지와 채널 스택하여 패치 토큰화 전에 초기 융합하는 선택을 합니다.

---

### Conclusion

현재 Octo 모델이 손목 카메라 정보를 적절하게 처리하는 데 어려움을 겪으며, 종종 3인칭 카메라만 사용할 때가 3인칭 및 손목 카메라를 결합할 때보다 미세 조정 결과가 더 강력하다는 것을 발견했습니다. 언어 조건부 정책 성능과 목표 조건부 정책 성능 사이에 큰 차이가 있음을 확인했습니다.

800k 로봇 궤적에 대해 사전 훈련된 대규모 트랜스포머 기반 확산 정책인 Octo 모델을 출시했습니다. Octo가 다양한 작업을 즉시 (out-of-the-box) 해결할 수 있음을 입증했으며, Octo의 구성적 설계가 새로운 입력 및 행동 공간으로 미세 조정을 가능하게 하여 광범위한 로봇 제어 문제에 대한 다재다능한 초기화가 됨을 보여주었습니다.

---

### 참고 자료

[원본 경로 #1](https://octo-models.github.io/paper.pdf)
