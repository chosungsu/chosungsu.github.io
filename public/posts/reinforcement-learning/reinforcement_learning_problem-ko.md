---
title: 'The Reinforcement Learning Problem'
date: '2025-03-03'
tags: ['reinforcement learning', 'lecture']
---

### Foundational Idea of Learning

환경과의 상호작용을 통해 학습한다는 아이디어는 학습의 본질을 생각할 때 가장 먼저 떠오릅니다. 유아가 놀거나 팔을 흔들거나 주위를 둘러볼 때, 명시적인 교사는 없지만 환경과 직접적인 감각-운동 연결을 가지고 있습니다. 이러한 연결을 실행함으로써 원인과 결과, 행동의 결과, 그리고 목표 달성을 위해 무엇을 해야 하는지에 대한 풍부한 정보를 얻습니다.

행동에 환경이 어떻게 반응하는지 명확하게 인식하며 행동을 통해 발생하는 일에 영향을 미치려 합니다. 상호작용을 통한 학습은 거의 모든 학습 및 지능 이론의 기본이 되는 아이디어입니다.

---

### Reinforcement Learning

강화 학습 문제는 수치적 보상 신호(numerical reward signal)를 최대화하기 위해 무엇을 해야 할지(상황을 행동에 매핑하는 방법)를 학습하는 것을 포함합니다.

폐쇄 루프에 의해 학습 시스템의 행동이 이후의 입력에 영향을 미칩니다. 그리고 학습자는 어떤 행동을 취해야 하는지 직접 지시받지 않으며 시도해 봄으로써 가장 많은 보상을 산출하는 행동을 발견해야 합니다. 행동의 결과가 확장된 시간 기간에 걸쳐 나타납니다.

#### The Exploration–Exploitation Dilemma

강화 학습에서 발생하는 도전 과제 중 하나는 탐험(Exploration)과 활용(Exploitation) 사이의 균형입니다. 많은 보상을 얻기 위해 과거에 시도해서 효과적이라고 입증된 행동을 선호해야 하고 더 나은 행동을 발견하기 위해 이전에 선택하지 않았던 행동을 시도해야 합니다.

---

### Examples of Reinforcement Learning

몇 가지 기본적인 특징을 공유합니다.

능동적인 의사 결정 에이전트와 환경 간의 상호작용을 포함하고 환경에 대한 불확실성에도 불구하고 목표를 달성하고자 합니다. 동시에 행동의 효과는 완전히 예측될 수 없어서 모니터링이 필요합니다.

에이전트는 로봇이나 유기체일 필요는 없으며 환경이 반드시 이 외부에 해당하는 것은 아닙니다.

---

### Elements of Reinforcement Learning

에이전트와 환경 외에도 강화 학습 시스템에는 정책, 보상, 가치함수, 모델 이렇게 네 가지 주요 하위 요소가 있습니다.

#### Policy

정책은 인지된 환경 상태를 해당 상태에서 취해야 할 행동으로 매핑하는 것으로 확률적인 핵심입니다.

#### Reward Signal

매 시간 단계마다 환경은 하나의 숫자인 보상을 보냅니다. 에이전트의 유일한 목표는 장기적으로 자신이 받는 총 보상을 최대화하는 것입니다.

#### Value Function

어떤 상태의 가치는 해당 상태에서 시작하여 에이전트가 미래에 축적할 것으로 예상되는 총 보상의 양입니다. 보상은 환경 상태의 즉각적이고 내재적인 바람직함을 결정하고 후속 상태와 그 상태에서 이용 가능한 보상을 고려합니다. 보상은 1차적인 반면 가치는 보상에 대한 예측으로 2차적입니다.

#### Model of the Environment

모델은 환경의 행동을 모방하거나, 환경이 어떻게 행동할지에 대한 추론을 가능하게 하는 것입니다. 모델과 계획을 사용하는 방법을 model based이고 모델을 사용하지 않는 더 단순한 방법을 model free 방법입니다.

---

### Limitations and Scope

유전 알고리즘(genetic algorithms), 유전 프로그래밍(genetic programming), 시뮬레이티드 어닐링(simulated annealing)과 같은 일부 최적화 방법들은 가치 함수를 사용하지 않고 강화 학습 문제에 접근해 왔습니다.

진화론적 방법은 강화 학습 문제의 유용한 구조를 무시하고, 에이전트가 어떤 상태를 통과하거나 어떤 행동을 선택하는지 활용하지 않습니다.

정책 경사 방법은 수치적 매개변수 집합으로 정의된 정책 공간을 탐색합니다. 에이전트가 환경과 상호작용하는 동안 정책의 성능을 가장 빠르게 향상시키기 위해 매개변수를 조정해야 하는 방향을 추정합니다.

---

### 참고 자료

[원본 경로 #1](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf?utm_source=chatgpt.com)

