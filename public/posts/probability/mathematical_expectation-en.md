---
title: 'Mathematical expectation'
date: '2023-05-05'
tags: ['Probability', 'lecture']
---

### Measurable Functions and Random Variables

A random variable is a function $X$ defined on the sample space $\Omega$ for which we can discuss the probability of events such as $\{\omega : X(\omega) \in A\}$.

#### Extended Real Line $\bar{\mathbb{R}}$

For many purposes it is convenient to allow a random variable to take the values $\pm \infty$. For instance, if we flip a fair coin repeatedly, the waiting time $X$ until the first head equals $\mathbf{+\infty}$ on the outcome where every flip is tails ($T, T, T, \dots$).

We reserve the term random variable for $\mathbb{R}$-valued functions, while measurable function refers to $\bar{\mathbb{R}}$-valued functions.

#### Checking Measurability

$\Rightarrow$ $X: \Omega \to \bar{\mathbb{R}}$ is measurable.

$\Rightarrow$ For every $a \in \mathbb{R}$, $\{X < a\} \in \mathcal{F}$.

$\Rightarrow$ For every $a \in \mathbb{R}$, $\{X \le a\} \in \mathcal{F}$.

$\Rightarrow$ For every $a \in \mathbb{R}$, $\{X > a\} \in \mathcal{F}$.

$\Rightarrow$ For every $a \in \mathbb{R}$, $\{X \ge a\} \in \mathcal{F}$.

The statements above are equivalent criteria for measurability.

---

### Integration with Respect to Measures

The expectation of a random variable is fundamentally an integral. We define the integral $\int_\Omega X \, d\mu$ for a general measure $\mu$ and a measurable function $X$.

For indicator functions $X(\omega) = \mathbf{1}_A(\omega)$ with $A \in \mathcal{F}$, define $\int_\Omega X \, d\mu \triangleq \mu(A)$.

A nonnegative simple measurable function $X \in \mathcal{S}^+$ on $\Omega$ is a finite linear combination of indicator functions,

$$
X(\omega) = \sum_{i=1}^n a_i \mathbf{1}_{A_i}(\omega).
$$

If $X \in \mathcal{S}^+$ and $X = \sum_{i=1}^n a_i \mathbf{1}_{A_i}$, then the integral of $X$ with respect to $\mu$ is defined as

$$
\int_\Omega X \, d\mu \triangleq \sum_{i=1}^n a_i \mu(A_i).
$$

These simple-function integrals satisfy linearity—$\int_\Omega (X + Y) \, d\mu = \int_\Omega X \, d\mu + \int_\Omega Y \, d\mu$ and $\int_\Omega \alpha X \, d\mu = \alpha \int_\Omega X \, d\mu$—as well as monotonicity: $X \le Y$ implies $\int_\Omega X \, d\mu \le \int_\Omega Y \, d\mu$.

---

### Taking Limits Under the Integral Sign

#### Monotone Convergence Theorem (MCT)

This theorem applies to nonnegative sequences and is used when convergence occurs monotonically.

If $X_n, X \ge 0$ and $X_n$ increases to $X$, then $\int_\Omega X_n \, d\mu$ increases to $\int_\Omega X \, d\mu$.

#### Fatou's Lemma

Fatou's lemma also applies to nonnegative sequences and works under weaker convergence assumptions.

For a sequence of measurable functions with $X_n \ge 0$, we have

$$
\int_\Omega \liminf_{n\to\infty} X_n \, d\mu \le \liminf_{n\to\infty} \int_\Omega X_n \, d\mu.
$$

#### Dominated Convergence Theorem (DCT)

The DCT removes the requirement $X_n \ge 0$ but demands uniform control of magnitudes.

Let $X_n, X, Y$ be measurable functions. If $|X_n| \le Y$ for all $n$, $X_n \to X$, and $Y \in L^1$, then $X \in L^1$ and

$$
\lim_{n\to\infty} \int_\Omega X_n \, d\mu = \int_\Omega X \, d\mu.
$$

---

### The Mathematical Expectation of a Random Variable

When the measure $\mu$ is a probability measure $\mathbf{P}$, the integral is called the mathematical expectation.

If the integral $\int_\Omega X \, d\mathbf{P}$ exists for a random variable $X$ on the probability space $(\Omega, \mathcal{F}, \mathbf{P})$, we call it the expectation of $X$ and denote it $\mathbf{E}[X]$.

The probability measure $\mu_X$ induced on $\mathcal{B}(\mathbb{R})$ by $X$ is called the law of $X$. The measure $\mu_X$ is the Lebesgue-Stieltjes measure generated by the distribution function $F_X(x) = \mathbf{P}(X \le x)$.

#### Some Inequalities

Markov's inequality states that for a random variable $X$ and parameters $\alpha, \lambda > 0$,

$$
\mathbf{P}(|X| \ge \lambda) \le \frac{\mathbf{E}[|X|^\alpha]}{\lambda^\alpha}.
$$

When $\alpha = 2$ and $X$ is replaced by $X - \mathbf{E}[X]$, we obtain Chebyshev's inequality, which provides a probability upper bound in terms of the variance.

---

### The Conditional Expectation

Let $X$ be an integrable random variable and let $\mathcal{G} \subseteq \mathcal{F}$ be a sub-$\sigma$-algebra. We define the conditional expectation $\mathbf{E}[X \mid \mathcal{G}]$ as a $\mathcal{G}$-measurable integrable random variable $Y$ satisfying

$$
\int_A Y \, d\mathbf{P} = \int_A X \, d\mathbf{P}
$$

for every $A \in \mathcal{G}$.

---

### References

[Original Source #1](https://researchers.ms.unimelb.edu.au/~xgge@unimelb/Files/Notes/Lecture%20Notes%20on%20Advanced%20Probability.pdf)

[Original Source #2](https://minerva.it.manchester.ac.uk/~saralees/statbook2.pdf)
