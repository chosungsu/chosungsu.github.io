---
title: 'Text numeral normalization'
date: '2025-02-07'
description: 'Develop an LLM-based NLP model that transforms Korean-written numerals (e.g., â€œì‚¼ì‹­ì´â€) into standard numeric forms (e.g., â€œ32â€)'
tags: ['seq2seq', 't5', 'llm']
github: 'https://github.com/username/project'
---

### Project Overview  
This project aimed to develop an LLM-based NLP model that transforms Korean-written numerals (e.g., â€œì‚¼ì‹­ì´â€) into standard numeric forms (e.g., â€œ32â€).  
The goal was to enhance information usability by normalizing numeric expressions within scripts generated by AI Humans, enabling downstream tasks like dialogue understanding and structured data extraction.

---

### Problem Definition  
Korean numerals are often expressed in diverse and irregular ways in text (e.g., â€œìŠ¤ë¬´ê°œâ€, â€œí•œë‘ ë²ˆâ€), making it difficult to normalize them using rule-based methods.  
The core idea was to utilize __contextual understanding__ powered by LLMs, since the same expression could mean different numbers depending on context.

---

### Approach & Technical Stack  

#### ğŸ§  Model Design and Application  
- Applied a __Seq2Seq model__ based on __pko-t5-large__, optimized for sentence understanding and transformation  
- Transformed full sentences to generate the appropriate normalized numeric form using context-aware generation

#### ğŸ”§ Data Preprocessing and Learning Strategy  
- Collected diverse Korean numeric expressions and __standardized irregular patterns__ to improve training quality  
- Applied a __custom loss function__ to enhance attention to numeral positions and improve contextual understanding  
- Used GPT to __augment the dataset__ with diverse sentence structures, improving generalization performance

---

### Results & Achievements  

- __7% improvement__ in accuracy (ACC) after standardizing irregular numeral patterns  
- An additional __10% improvement__ through GPT-based data augmentation  
- Outperformed rule-based approaches by over 15% accuracy on some sentence types

---

### Conclusion  
This project demonstrated the potential of LLMs in extracting and normalizing numeric expressions in Korean, outperforming traditional rule-based methods.  
In the future, we aim to expand this approach to domain-specific texts such as finance, healthcare, and legal documents.
